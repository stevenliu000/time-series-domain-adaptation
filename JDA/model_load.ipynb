{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as F\n",
    "from martins.complex_transformer import ComplexTransformer\n",
    "from dataset import TimeSeriesDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fake args\n",
    "parameters = {\n",
    "    'data_path': '/home/tianqinl/time-series-domain-adaptation/data_unzip/',\n",
    "    'train_file': 'train_{}.pkl',\n",
    "    'vali_file': 'validation_{}.pkl',\n",
    "    'task': '3Av2',\n",
    "    'batch_size': 32,\n",
    "    'lr_clf': 1e-3,\n",
    "    'epochs': 2,\n",
    "    'PATH': '/home/tianqinl/time-series-domain-adaptation/JDA/data_resultsb400.e500.lr0.0001.task3Av2'\n",
    "}\n",
    "\n",
    "class ARGS:\n",
    "    def __init__(self, parameters):\n",
    "        self.data_path = parameters['data_path']\n",
    "        self.train_file = parameters['train_file']\n",
    "        self.vali_file = parameters['vali_file']\n",
    "        self.task = parameters['task']\n",
    "        self.batch_size = parameters['batch_size']\n",
    "        self.lr_clf = parameters['lr_clf']\n",
    "        self.epochs = parameters['epochs']\n",
    "        self.PATH = parameters['PATH']\n",
    "\n",
    "\n",
    "args = ARGS(parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model(x, y, model_dir=\"FNN_trained_model/Final_FNN_3Av2/\", epoch=\"model.ep100\", task = \"3Av2\"):\n",
    "    \n",
    "    class FNN(nn.Module):\n",
    "        def __init__(self, d_in, d_h, d_out, dp):\n",
    "            super(FNN, self).__init__()\n",
    "            self.fc1 = nn.Linear(d_in, d_h)\n",
    "            self.fc2 = nn.Linear(d_h, d_out)\n",
    "            self.dp = nn.Dropout(dp)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.fc1(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.dp(x)\n",
    "            x = self.fc2(x)\n",
    "\n",
    "            return x\n",
    "\n",
    "\n",
    "    \n",
    "    seq_len = 10\n",
    "    feature_dim = 160\n",
    "    d_out = 50 if task == \"3Av2\" else 65\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "    \n",
    "    CNet_path = model_dir + \"CNet_\" + epoch\n",
    "    encoder_path = model_dir + \"Encoder_\" + epoch\n",
    "    \n",
    "    CNet = FNN(d_in=feature_dim * 2 * seq_len, d_h=500, d_out=d_out, dp=0.5)\n",
    "    \n",
    "    encoder = ComplexTransformer(layers=1,\n",
    "                               time_step=seq_len,\n",
    "                               input_dim=feature_dim,\n",
    "                               hidden_size=512,\n",
    "                               output_dim=512,\n",
    "                               num_heads=8,\n",
    "                               out_dropout=0.5)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        CNet.load_state_dict(torch.load(CNet_path))\n",
    "        encoder.load_state_dict(torch.load(encoder_path))\n",
    "    else:\n",
    "        CNet.load_state_dict(torch.load(CNet_path, map_location=torch.device('cpu')))\n",
    "        encoder.load_state_dict(torch.load(encoder_path, map_location=torch.device('cpu')))\n",
    "    batch_size = x.shape[0]\n",
    "    CNet.eval()\n",
    "    encoder.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        #normalize data\n",
    "        x = (x - x_mean_tr) / x_std_tr\n",
    "        # take the real and imaginary part out\n",
    "        real = x[:,:,0].reshape(batch_size, seq_len, feature_dim).float()\n",
    "        imag = x[:,:,1].reshape(batch_size, seq_len, feature_dim).float()\n",
    "        if torch.cuda.is_available():\n",
    "            real.to(device)\n",
    "            imag.to(device)\n",
    "        real, imag = encoder(real, imag)\n",
    "        pred = CNet(torch.cat((real, imag), -1).reshape(x.shape[0], -1))\n",
    "        loss = criterion(pred, y.argmax(-1))\n",
    "        \n",
    "    return pred, loss, CNet, encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [00:07<00:00, 20.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " validation_acc: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "\n",
    "training_set = TimeSeriesDataset(root_dir=args.data_path, file_name=args.train_file.format(args.task), train=True)\n",
    "vali_set = TimeSeriesDataset(root_dir=args.data_path, file_name=args.vali_file.format(args.task), train=True)\n",
    "# test_set = TimeSeriesDataset(root_dir=args.data_path, file_name=args.file.format(args.task), train=False)\n",
    "\n",
    "train_loader = DataLoader(training_set, batch_size=args.batch_size, shuffle=True)\n",
    "vali_loader = DataLoader(vali_set, batch_size=args.batch_size, shuffle=True)\n",
    "# test_loader = DataLoader(test_set, batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "# Encoding by complex transformer\n",
    "x_mean_tr = training_set.data_mean\n",
    "x_std_tr = training_set.data_std\n",
    "\n",
    "preds = []\n",
    "correct_vali = 0\n",
    "total_bs_vali = 0\n",
    "vali_loss = 0\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for batch_id, (x, y) in enumerate(tqdm(train_loader)):\n",
    "    if torch.cuda.is_available():\n",
    "        x, y = x.to(device), y.to(device)\n",
    "    ############ Call Model ############\n",
    "    pred, loss, _, _ = call_model(x, y)\n",
    "    ####################################\n",
    "    #print(pred.argmax(-1), y.argmax(-1))\n",
    "    correct_vali += (pred.argmax(-1) == y.argmax(-1)).sum().item()\n",
    "    total_bs_vali += y.shape[0]\n",
    "    \n",
    "vali_acc = float(correct_vali) / total_bs_vali\n",
    "vali_log_str = \" validation_acc: \"+ str(vali_acc)\n",
    "preds.append(pred)\n",
    "\n",
    "print(vali_log_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
