{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as F\n",
    "from martins.complex_transformer import ComplexTransformer\n",
    "from dataset import TimeSeriesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/tianqinli/Code/Working-on/time-series-domain-adaptation/JDA'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake args\n",
    "parameters = {\n",
    "    'data_path': '/Users/tianqinli/Code/Working-on/Russ/time-series-domain-adaptation/data_unzip/',\n",
    "    'file': 'processed_file_{}.pkl',\n",
    "    'task': '3Av2',\n",
    "    'batch_size': 32,\n",
    "    'lr_clf': 1e-3,\n",
    "    'epochs': 2,\n",
    "    'PATH': '/Users/tianqinli/Code/Working-on/Russ/time-series-domain-adaptation/JDA/data_results/models/'\n",
    "}\n",
    "\n",
    "class ARGS:\n",
    "    def __init__(self, parameters):\n",
    "        self.data_path = parameters['data_path']\n",
    "        self.file = parameters['file']\n",
    "        self.task = parameters['task']\n",
    "        self.batch_size = parameters['batch_size']\n",
    "        self.lr_clf = parameters['lr_clf']\n",
    "        self.epochs = parameters['epochs']\n",
    "        self.path = parameters['PATH']\n",
    "\n",
    "        \n",
    "args = ARGS(parameters)\n",
    "# other parameters\n",
    "seq_len = 10 \n",
    "feature_dim = 160\n",
    "d_out = 50 if args.task == \"3Av2\" else 65\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNN(nn.Module):\n",
    "    def __init__(self, d_in, d_h, d_out, dp):\n",
    "        super(FNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_in, d_h)\n",
    "        self.fc2 = nn.Linear(d_h, d_out)\n",
    "        self.dp = nn.Dropout(dp)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dp(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "from dataset import TimeSeriesDataset\n",
    "\n",
    "\n",
    "training_set = TimeSeriesDataset(root_dir=args.data_path, file_name=args.file.format(args.task), train=True)\n",
    "test_set = TimeSeriesDataset(root_dir=args.data_path, file_name=args.file.format(args.task), train=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(training_set, batch_size=args.batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=args.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dataset.TimeSeriesDataset at 0x2634742390>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for data loader\n",
    "tmp = 0\n",
    "for batch_id, (x, y) in enumerate(train_loader):\n",
    "#     print(batch_id)\n",
    "#     print(x.shape)\n",
    "#     print(y.shape)\n",
    "    tmp += x.shape[0]\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make complex transformer\n",
    "\n",
    "encoder = ComplexTransformer(layers=1, \n",
    "                               time_step=seq_len, \n",
    "                               input_dim=feature_dim, \n",
    "                               hidden_size=512, \n",
    "                               output_dim=512, \n",
    "                               num_heads=8,\n",
    "                               out_dropout=0.5)\n",
    "\n",
    "if torch.cuda.is_available(): encoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:27<00:00,  5.62it/s]\n",
      "  0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc: 0.151; train_loss: 3.465614217376709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:30<00:00,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc: 0.232; train_loss: 2.867535138320923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CNet = FNN(d_in=feature_dim * 2 * seq_len, d_h=500, d_out=d_out, dp=0.5)\n",
    "if torch.cuda.is_available(): \n",
    "    CNet = CNet.to(device)\n",
    "\n",
    "params = list(encoder.parameters()) + list(CNet.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if torch.cuda.is_available(): \n",
    "    criterion = criterion.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(params, lr=args.lr_clf)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
    "    \n",
    "    \n",
    "# Encoding by complex transformer\n",
    "x_mean_tr = training_set.data_mean\n",
    "x_std_tr = training_set.data_std \n",
    "\n",
    "x_mean_te = test_set.data_mean\n",
    "x_std_te = test_set.data_std\n",
    "\n",
    "best_acc_train = best_acc_test = 0\n",
    "\n",
    "if not os.path.isdir(args.path):\n",
    "    os.mkdir(args.path)\n",
    "    \n",
    "#### train\n",
    "for epoch in range(args.epochs):\n",
    "    \"\"\"Training\"\"\"\n",
    "    correct_train = 0\n",
    "    total_bs_train = 0 # total batch size\n",
    "    train_loss = 0\n",
    "    for batch_id, (x, y) in enumerate(tqdm(train_loader)):\n",
    "        if torch.cuda.is_available():\n",
    "            x, y = x.to(device), y.to(device) \n",
    "        batch_size = x.shape[0]\n",
    "        #normalize data\n",
    "        x = (x - x_mean_tr) / x_std_tr\n",
    "        # take the real and imaginary part out\n",
    "        real = x[:,:,0].reshape(batch_size, seq_len, feature_dim).float()\n",
    "        imag = x[:,:,1].reshape(batch_size, seq_len, feature_dim).float()\n",
    "        if torch.cuda.is_available(): \n",
    "            real.to(device)\n",
    "            imag.to(device)\n",
    "        real, imag = encoder(real, imag)\n",
    "        pred = CNet(torch.cat((real, imag), -1).reshape(x.shape[0], -1)) \n",
    "        loss = criterion(pred, y.argmax(-1))\n",
    "        #print(pred.argmax(-1), y.argmax(-1))\n",
    "        correct_train += (pred.argmax(-1) == y.argmax(-1)).sum().item()\n",
    "        total_bs_train += y.shape[0]\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * x.shape[0]\n",
    "    train_acc = float(correct_train) / total_bs_train\n",
    "    train_loss = train_loss / total_bs_train\n",
    "    best_acc_train = max(best_acc_train, train_acc)\n",
    "    \n",
    "    PATH = args.path + \"model.ep\" + str(epoch)\n",
    "    torch.save(CNet.state_dict(), PATH)\n",
    "    print(\"train_acc: \"+ str(train_acc) + \"; train_loss: \" + str(train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0536"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test saved "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isdir(args.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
