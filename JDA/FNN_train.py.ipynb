{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as F\n",
    "from martins.complex_transformer import ComplexTransformer\n",
    "from dataset import TimeSeriesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/tianqinli/Code/Working-on/time-series-domain-adaptation/JDA'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake args\n",
    "parameters = {\n",
    "    'data_path': '/Users/tianqinli/Code/Working-on/Russ/time-series-domain-adaptation/data_unzip/',\n",
    "    'file': 'processed_file_{}.pkl',\n",
    "    'task': '3Av2',\n",
    "    'batch_size': 32,\n",
    "    'lr_clf': 1e-3,\n",
    "    'epochs': 2,\n",
    "    'PATH': '/Users/tianqinli/Code/Working-on/Russ/time-series-domain-adaptation/JDA/data_results/models/'\n",
    "}\n",
    "\n",
    "class ARGS:\n",
    "    def __init__(self, parameters):\n",
    "        self.data_path = parameters['data_path']\n",
    "        self.file = parameters['file']\n",
    "        self.task = parameters['task']\n",
    "        self.batch_size = parameters['batch_size']\n",
    "        self.lr_clf = parameters['lr_clf']\n",
    "        self.epochs = parameters['epochs']\n",
    "        self.path = parameters['PATH']\n",
    "\n",
    "        \n",
    "args = ARGS(parameters)\n",
    "# other parameters\n",
    "seq_len = 10 \n",
    "feature_dim = 160\n",
    "d_out = 50 if args.task == \"3Av2\" else 65\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNN(nn.Module):\n",
    "    def __init__(self, d_in, d_h, d_out, dp):\n",
    "        super(FNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_in, d_h)\n",
    "        self.fc2 = nn.Linear(d_h, d_out)\n",
    "        self.dp = nn.Dropout(dp)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dp(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "from dataset import TimeSeriesDataset\n",
    "\n",
    "\n",
    "training_set = TimeSeriesDataset(root_dir=args.data_path, file_name=args.file.format(args.task), train=True)\n",
    "test_set = TimeSeriesDataset(root_dir=args.data_path, file_name=args.file.format(args.task), train=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(training_set, batch_size=args.batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=args.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dataset.TimeSeriesDataset at 0x2634742390>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for data loader\n",
    "tmp = 0\n",
    "for batch_id, (x, y) in enumerate(train_loader):\n",
    "#     print(batch_id)\n",
    "#     print(x.shape)\n",
    "#     print(y.shape)\n",
    "    tmp += x.shape[0]\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make complex transformer\n",
    "\n",
    "encoder = ComplexTransformer(layers=1, \n",
    "                               time_step=seq_len, \n",
    "                               input_dim=feature_dim, \n",
    "                               hidden_size=512, \n",
    "                               output_dim=512, \n",
    "                               num_heads=8,\n",
    "                               out_dropout=0.5)\n",
    "\n",
    "if torch.cuda.is_available(): encoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:27<00:00,  5.62it/s]\n",
      "  0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc: 0.151; train_loss: 3.465614217376709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:30<00:00,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc: 0.232; train_loss: 2.867535138320923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CNet = FNN(d_in=feature_dim * 2 * seq_len, d_h=500, d_out=d_out, dp=0.5)\n",
    "if torch.cuda.is_available(): \n",
    "    CNet = CNet.to(device)\n",
    "\n",
    "params = list(encoder.parameters()) + list(CNet.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if torch.cuda.is_available(): \n",
    "    criterion = criterion.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(params, lr=args.lr_clf)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
    "    \n",
    "    \n",
    "# Encoding by complex transformer\n",
    "x_mean_tr = training_set.data_mean\n",
    "x_std_tr = training_set.data_std \n",
    "\n",
    "x_mean_te = test_set.data_mean\n",
    "x_std_te = test_set.data_std\n",
    "\n",
    "best_acc_train = best_acc_test = 0\n",
    "\n",
    "if not os.path.isdir(args.path):\n",
    "    os.mkdir(args.path)\n",
    "    \n",
    "#### train\n",
    "for epoch in range(args.epochs):\n",
    "    \"\"\"Training\"\"\"\n",
    "    correct_train = 0\n",
    "    total_bs_train = 0 # total batch size\n",
    "    train_loss = 0\n",
    "    for batch_id, (x, y) in enumerate(tqdm(train_loader)):\n",
    "        if torch.cuda.is_available():\n",
    "            x, y = x.to(device), y.to(device) \n",
    "        batch_size = x.shape[0]\n",
    "        #normalize data\n",
    "        x = (x - x_mean_tr) / x_std_tr\n",
    "        # take the real and imaginary part out\n",
    "        real = x[:,:,0].reshape(batch_size, seq_len, feature_dim).float()\n",
    "        imag = x[:,:,1].reshape(batch_size, seq_len, feature_dim).float()\n",
    "        if torch.cuda.is_available(): \n",
    "            real.to(device)\n",
    "            imag.to(device)\n",
    "        real, imag = encoder(real, imag)\n",
    "        pred = CNet(torch.cat((real, imag), -1).reshape(x.shape[0], -1)) \n",
    "        loss = criterion(pred, y.argmax(-1))\n",
    "        #print(pred.argmax(-1), y.argmax(-1))\n",
    "        correct_train += (pred.argmax(-1) == y.argmax(-1)).sum().item()\n",
    "        total_bs_train += y.shape[0]\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * x.shape[0]\n",
    "    train_acc = float(correct_train) / total_bs_train\n",
    "    train_loss = train_loss / total_bs_train\n",
    "    best_acc_train = max(best_acc_train, train_acc)\n",
    "    \n",
    "    PATH = args.path + \"model.ep\" + str(epoch)\n",
    "    torch.save(CNet.state_dict(), PATH)\n",
    "    print(\"train_acc: \"+ str(train_acc) + \"; train_loss: \" + str(train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0536"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test saved "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isdir(args.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--data_path DATA_PATH]\n",
      "                             [--train_file TRAIN_FILE] [--vali_file VALI_FILE]\n",
      "                             [--task TASK] [--batch_size BATCH_SIZE]\n",
      "                             [--lr_clf LR_CLF] [--epochs EPOCHS] [--PATH PATH]\n",
      "                             [--log LOG]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/tianqinl/.local/share/jupyter/runtime/kernel-324ef629-d09e-45c7-b2f8-3a4d11f4a37b.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as F\n",
    "from martins.complex_transformer import ComplexTransformer\n",
    "from dataset import TimeSeriesDataset\n",
    "\n",
    "import argparse\n",
    "\n",
    "# parser = argparse.ArgumentParser(description='Time series adaptation')\n",
    "# parser.add_argument(\"--data_path\", type=str, default=\"/Users/tianqinli/Code/Working-on/Russ/time-series-domain-adaptation/data_unzip/\", help=\"dataset folder path\")\n",
    "# parser.add_argument('--train_file', type=str, default=\"train_{}.pkl\", help='which training file to perform')\n",
    "# parser.add_argument('--vali_file', type=str, default=\"validation_{}.pkl\", help='which validation file to perform')\n",
    "# parser.add_argument(\"--task\", type=str, default=\"3Av2\", help='3Av2 or 3E')\n",
    "# parser.add_argument('--batch_size', type=int, default=256, help='batch size')\n",
    "# parser.add_argument('--lr_clf', type=float, default=1e-4, help='learning rate for classification')\n",
    "# parser.add_argument('--epochs', type=int, default=50, help='number of epochs')\n",
    "# parser.add_argument('--PATH', type=str, default= \"/Users/tianqinli/Code/Working-on/Russ/time-series-domain-adaptation/JDA/data_results/\", help='Model save location')\n",
    "# parser.add_argument('--log', type=str, default=\"FNN_log.out\", help=\"Output log file for training and validation loss\")\n",
    "\n",
    "\n",
    "# fake args\n",
    "parameters = {\n",
    "    'data_path': '/Users/tianqinli/Code/Working-on/Russ/time-series-domain-adaptation/data_unzip/',\n",
    "    'train_file': 'train_{}.pkl',\n",
    "    'vali_file': 'validation_{}.pkl',\n",
    "    'task': '3Av2',\n",
    "    'batch_size': 32,\n",
    "    'lr_clf': 1e-3,\n",
    "    'epochs': 2,\n",
    "    'PATH': '/Users/tianqinli/Code/Working-on/Russ/time-series-domain-adaptation/JDA/data_results/models/'\n",
    "}\n",
    "\n",
    "class ARGS:\n",
    "    def __init__(self, parameters):\n",
    "        self.data_path = parameters['data_path']\n",
    "        self.train_file = parameters['train_file']\n",
    "        self.vali_file = parameters['vali_file']\n",
    "        self.task = parameters['task']\n",
    "        self.batch_size = parameters['batch_size']\n",
    "        self.lr_clf = parameters['lr_clf']\n",
    "        self.epochs = parameters['epochs']\n",
    "        self.PATH = parameters['PATH']\n",
    "\n",
    "\n",
    "# args = ARGS(parameters)\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "# other parameters\n",
    "seq_len = 10\n",
    "feature_dim = 160\n",
    "d_out = 50 if args.task == \"3Av2\" else 65\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "\n",
    "\n",
    "class FNN(nn.Module):\n",
    "    def __init__(self, d_in, d_h, d_out, dp):\n",
    "        super(FNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_in, d_h)\n",
    "        self.fc2 = nn.Linear(d_h, d_out)\n",
    "        self.dp = nn.Dropout(dp)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dp(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "training_set = TimeSeriesDataset(root_dir=args.data_path, file_name=args.train_file.format(args.task), train=True)\n",
    "vali_set = TimeSeriesDataset(root_dir=args.data_path, file_name=args.vali_file.format(args.task), train=True)\n",
    "# test_set = TimeSeriesDataset(root_dir=args.data_path, file_name=args.file.format(args.task), train=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(training_set, batch_size=args.batch_size, shuffle=True)\n",
    "vali_loader = DataLoader(vali_set, batch_size=args.batch_size, shuffle=True)\n",
    "# test_loader = DataLoader(test_set, batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "encoder = ComplexTransformer(layers=1,\n",
    "                               time_step=seq_len,\n",
    "                               input_dim=feature_dim,\n",
    "                               hidden_size=512,\n",
    "                               output_dim=512,\n",
    "                               num_heads=8,\n",
    "                               out_dropout=0.5)\n",
    "\n",
    "if torch.cuda.is_available(): encoder.to(device)\n",
    "\n",
    "\n",
    "CNet = FNN(d_in=feature_dim * 2 * seq_len, d_h=500, d_out=d_out, dp=0.5)\n",
    "if torch.cuda.is_available():\n",
    "    CNet = CNet.to(device)\n",
    "\n",
    "params = list(encoder.parameters()) + list(CNet.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    criterion = criterion.cuda()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(params, lr=args.lr_clf)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
    "\n",
    "\n",
    "# Encoding by complex transformer\n",
    "x_mean_tr = training_set.data_mean\n",
    "x_std_tr = training_set.data_std\n",
    "\n",
    "#x_mean_te = test_set.data_mean\n",
    "#x_std_te = test_set.data_std\n",
    "\n",
    "best_acc_train = best_acc_test = 0\n",
    "\n",
    "unique_id = \"b\" + str(args.batch_size) + \".e\" + str(args.epochs) + \".lr\" + str(args.lr_clf) + \".task\" + args.task\n",
    "\n",
    "\n",
    "folder_path = args.PATH[:-1] + unique_id + \"/\"\n",
    "if not os.path.isdir(folder_path):\n",
    "    os.mkdir(folder_path)\n",
    "\n",
    "\n",
    "\n",
    "logfile_full_path = folder_path + args.log + unique_id\n",
    "with open(logfile_full_path, 'w') as f:\n",
    "    f.write(\"Epoch\\tTime\\ttrain_acc\\ttrain_loss\\tvalidation_acc\")\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "#### train\n",
    "for epoch in range(args.epochs):\n",
    "    \"\"\"Training\"\"\"\n",
    "    correct_train = 0\n",
    "    total_bs_train = 0 # total batch size\n",
    "    train_loss = 0\n",
    "    start_train_time = time.time()\n",
    "    for batch_id, (x, y) in enumerate(tqdm(train_loader)):\n",
    "        if torch.cuda.is_available():\n",
    "            x, y = x.to(device), y.to(device)\n",
    "        batch_size = x.shape[0]\n",
    "        #normalize data\n",
    "        x = (x - x_mean_tr) / x_std_tr\n",
    "        # take the real and imaginary part out\n",
    "        real = x[:,:,0].reshape(batch_size, seq_len, feature_dim).float()\n",
    "        imag = x[:,:,1].reshape(batch_size, seq_len, feature_dim).float()\n",
    "        if torch.cuda.is_available():\n",
    "            real.to(device)\n",
    "            imag.to(device)\n",
    "        real, imag = encoder(real, imag)\n",
    "        pred = CNet(torch.cat((real, imag), -1).reshape(x.shape[0], -1))\n",
    "        loss = criterion(pred, y.argmax(-1))\n",
    "        #print(pred.argmax(-1), y.argmax(-1))\n",
    "        correct_train += (pred.argmax(-1) == y.argmax(-1)).sum().item()\n",
    "        total_bs_train += y.shape[0]\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * x.shape[0]\n",
    "    train_acc = float(correct_train) / total_bs_train\n",
    "    train_loss = train_loss / total_bs_train\n",
    "    best_acc_train = max(best_acc_train, train_acc)\n",
    "    \n",
    "    CNet_PATH = folder_path + \"CNet_\" + \"model.ep\" + str(epoch)\n",
    "    encoder_PATH = folder_path + \"Encoder_\" + \"model.ep\" + str(epoch)\n",
    "    torch.save(CNet.state_dict(), CNet_PATH)\n",
    "    torch.save(encode.state_dict(), encoder_PATH)\n",
    "\n",
    "    time_now = datetime.datetime.now()\n",
    "    end_train_time = time.time()\n",
    "    train_epoch_time = round(end_train_time - start_train_time, 2)\n",
    "    logstr = str(time_now) + \"\\nepoch \" + str(epoch) + \": train_acc: \"+ str(train_acc) + \"; train_loss: \" + str(train_loss)\n",
    "\n",
    "\n",
    "    with open(logfile_full_path, 'a') as f:\n",
    "        f.write(str(epoch) + \"\\t\" + str(train_epoch_time) + \"\\t\" + str(train_acc) + \"\\t\" + str(train_loss) + \"\\t\")\n",
    "\n",
    "\n",
    "    \"\"\"Testing\"\"\"\n",
    "    correct_vali = 0\n",
    "    total_bs_vali = 0\n",
    "    vali_loss = 0\n",
    "    for batch_id, (x, y) in enumerate(vali_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            x, y = x.to(device), y.to(device)\n",
    "        batch_size = x.shape[0]\n",
    "        CNet.eval()\n",
    "        encoder.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            #normalize data\n",
    "            x = (x - x_mean_tr) / x_std_tr\n",
    "            # take the real and imaginary part out\n",
    "            real = x[:,:,0].reshape(batch_size, seq_len, feature_dim).float()\n",
    "            imag = x[:,:,1].reshape(batch_size, seq_len, feature_dim).float()\n",
    "            if torch.cuda.is_available():\n",
    "                real.to(device)\n",
    "                imag.to(device)\n",
    "            real, imag = encoder(real, imag)\n",
    "            pred = CNet(torch.cat((real, imag), -1).reshape(x.shape[0], -1))\n",
    "            loss = criterion(pred, y.argmax(-1))\n",
    "            #print(pred.argmax(-1), y.argmax(-1))\n",
    "            correct_vali += (pred.argmax(-1) == y.argmax(-1)).sum().item()\n",
    "            total_bs_vali += y.shape[0]\n",
    "    vali_acc = float(correct_vali) / total_bs_vali\n",
    "    vali_log_str = \" validation_acc: \"+ str(vali_acc)\n",
    "\n",
    "    with open(logfile_full_path, 'a') as f:\n",
    "        f.write(str(vali_acc))\n",
    "        f.write(\"\\n\")\n",
    "    print(logstr + vali_log_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
