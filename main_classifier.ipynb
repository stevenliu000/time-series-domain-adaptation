{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import argparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesChunkDataset(data.Dataset):\n",
    "    def __init__(self, x, y, context):\n",
    "        super(TimeSeriesChunkDataset, self).__init__()\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.context = context\n",
    "        self.points_per_series = self.x.shape[1] - self.context + 1\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.x.shape[0] * self.points_per_series\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        index_series = index // self.points_per_series\n",
    "        index_point = index % self.points_per_series\n",
    "        return_x = self.x[index_series, index_point:index_point+self.context, :]\n",
    "        return_y = np.argmax(self.y[index_series, :])\n",
    "        return return_x, return_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, layers_size, dim_out, dropout=0.3):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.layers = []\n",
    "        self.activs = []\n",
    "        self.dropouts = []\n",
    "        self.layers_size = layers_size\n",
    "        \n",
    "        for i in range(len(layers_size)-1):\n",
    "            self.layers.append(nn.Linear(layers_size[i], layers_size[i+1]))\n",
    "            self.activs.append(nn.ReLU())\n",
    "            if i < len(layers_size)-2:\n",
    "                self.dropouts.append(nn.Dropout(p=dropout))\n",
    "\n",
    "        self.layers.append(nn.Linear(layers_size[-1], dim_out))\n",
    "        self.nlayer = len(self.layers)\n",
    "        self.nactivs = len(self.activs)\n",
    "        self.ndropouts = len(self.dropouts)\n",
    "\n",
    "        self.layers = nn.ModuleList(self.layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        for i in range(self.nlayer):\n",
    "            out = self.layers[i](out)\n",
    "            if i < self.nactivs:\n",
    "                out = self.activs[i](out)\n",
    "            if i < self.ndropouts:\n",
    "                out = self.dropouts[i](out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    '''\n",
    "    credit: from https://github.com/martinmamql/complex_da\n",
    "    '''\n",
    "    def __init__(self, feature_dim, d_out):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "\n",
    "            nn.Linear(feature_dim, feature_dim),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Linear(feature_dim, feature_dim),\n",
    "            nn.LayerNorm(feature_dim),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Linear(feature_dim, feature_dim),\n",
    "            nn.LayerNorm(feature_dim),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Linear(feature_dim, feature_dim),\n",
    "            nn.LayerNorm(feature_dim),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        ) \n",
    "        self.fc = nn.Linear(3200, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: [bs, seq, feature_dim]\n",
    "        x = self.net(x)\n",
    "        bs = x.shape[0]\n",
    "        x = x.reshape(bs, -1)\n",
    "        out = self.sigmoid(self.fc(x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Generator, self).__init__()\n",
    "        self.transformer_layer_args = {'d_model':2, 'nhead':1, 'dim_feedforward':1024, 'dropout':0.1, 'activation':'gelu'}\n",
    "        self.transformer_args = {'num_layers':3, 'norm':None}\n",
    "        self.transformer_layer_args.update(kwargs['transformer_layer'])\n",
    "        self.transformer_args.update(kwargs['transformer'])\n",
    "        \n",
    "        self.transformer_layer = nn.TransformerEncoderLayer(**self.transformer_layer_args)\n",
    "        self.transformer = nn.TransformerEncoder(self.transformer_layer, **self.transformer_args)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.transformer(x)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SourceDomainClassifier(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SourceDomainClassifier, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            Generator(**(kwargs[\"generator\"])),\n",
    "            nn.Flatten(),\n",
    "            Classifier(**(kwargs['classifier']))\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(preds, label):\n",
    "    class_preds = torch.argmax(preds, dim=1)\n",
    "    correct = torch.eq(class_preds, label).float()\n",
    "    acc = correct.sum()\n",
    "    return acc\n",
    "\n",
    "def inference(model, dataloader, device, testing=False):\n",
    "    model.eval()\n",
    "\n",
    "    if testing: \n",
    "        result = []\n",
    "    else:\n",
    "        inference_acc = 0.0\n",
    "\n",
    "    num_data = 0.0\n",
    "    with torch.no_grad():\n",
    "        for key, (x_batch, y_batch) in enumerate(dataloader):\n",
    "            num_data += y_batch.shape[0]\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.long().to(device)\n",
    "            preds = model(x_batch)\n",
    "            if testing:\n",
    "                result.extend(torch.argmax(nn.functional.softmax(preds, dim=1), dim=1).cpu().numpy())\n",
    "            else:\n",
    "                inference_acc += get_accuracy(preds, y_batch.squeeze_()).item()\n",
    "    \n",
    "\n",
    "    if testing:\n",
    "        return result\n",
    "    else:\n",
    "        return inference_acc / num_data\n",
    "    \n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.00)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, vali_dataloader, lr, n_epochs, device):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "#     scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.7, patience=3)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    train_loss_ = []\n",
    "    train_acc_ = []\n",
    "    vali_acc_ = []\n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "\n",
    "        num_data = 0.0\n",
    "        num_batches = len(train_dataloader)\n",
    "        for batches, (x_batch, y_batch) in tqdm(enumerate(train_dataloader), total=num_batches):\n",
    "            model.train()\n",
    "            num_data += y_batch.shape[0]\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.long().to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(x_batch)\n",
    "            loss = loss_fn(preds, y_batch.squeeze_())\n",
    "            acc = get_accuracy(preds, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            train_acc += acc.item()\n",
    "            \n",
    "            if batches > 1 and batches % int(num_batches/3) == 0:\n",
    "                vali_acc = inference(model, vali_dataloader, device)\n",
    "                print(\"validation_acc: \", vali_acc)\n",
    "\n",
    "        vali_acc = inference(model, vali_dataloader, device)\n",
    "        train_loss_.append(train_loss/num_data)\n",
    "        train_acc_.append(train_acc/num_data)\n",
    "        vali_acc_.append(vali_acc)\n",
    "        # scheduler.step(vali_acc)\n",
    "        name = \"model_\" + str(epoch) + \".t7\"   \n",
    "        np.save(\"train_loss_.npy\",train_loss_)\n",
    "        np.save(\"train_acc_.npy\",train_acc_)\n",
    "        np.save(\"vali_acc_.npy\",vali_acc_)\n",
    "        torch.save(model.state_dict(), name)\n",
    "\n",
    "        print(\"epoch {}: train_loss: {}, train_acc: {}, vali_acc: {}\".format(epoch, train_loss/num_data, train_acc/num_data, vali_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#local only\n",
    "\n",
    "class fake_args():\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "        \n",
    "args = fake_args(data_path='./data_unzip/', \n",
    "                 task='3A', \n",
    "                 batch_size=30,\n",
    "                 epochs=2,\n",
    "                 lr=1e-3,\n",
    "                 context=10)\n",
    "\n",
    "args.task = \"processed_file_3Av2.pkl\" if args.task == \"3A\" else \"processed_file_3E.pkl\"\n",
    "args.data_path = args.data_path + args.task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/478 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 4/478 [00:00<00:12, 37.79it/s]\u001b[A\n",
      "  2%|▏         | 10/478 [00:00<00:11, 41.13it/s]\u001b[A\n",
      "  3%|▎         | 15/478 [00:00<00:10, 42.67it/s]\u001b[A\n",
      "  4%|▍         | 20/478 [00:00<00:10, 43.94it/s]\u001b[A\n",
      "  5%|▌         | 25/478 [00:00<00:10, 44.99it/s]\u001b[A\n",
      "  6%|▋         | 30/478 [00:00<00:09, 46.18it/s]\u001b[A\n",
      "  8%|▊         | 36/478 [00:00<00:09, 47.59it/s]\u001b[A\n",
      "  9%|▉         | 42/478 [00:00<00:09, 48.27it/s]\u001b[A\n",
      " 10%|▉         | 47/478 [00:00<00:09, 47.05it/s]\u001b[A\n",
      " 11%|█         | 53/478 [00:01<00:08, 48.15it/s]\u001b[A\n",
      " 12%|█▏        | 59/478 [00:01<00:08, 49.19it/s]\u001b[A\n",
      " 13%|█▎        | 64/478 [00:01<00:08, 49.34it/s]\u001b[A\n",
      " 15%|█▍        | 70/478 [00:01<00:08, 49.84it/s]\u001b[A\n",
      " 16%|█▌        | 75/478 [00:01<00:08, 49.39it/s]\u001b[A\n",
      " 17%|█▋        | 80/478 [00:01<00:08, 48.72it/s]\u001b[A\n",
      " 18%|█▊        | 85/478 [00:01<00:08, 48.52it/s]\u001b[A\n",
      " 19%|█▉        | 91/478 [00:01<00:07, 49.53it/s]\u001b[A\n",
      " 20%|██        | 96/478 [00:01<00:07, 49.63it/s]\u001b[A\n",
      " 21%|██▏       | 102/478 [00:02<00:07, 50.03it/s]\u001b[A\n",
      " 23%|██▎       | 108/478 [00:02<00:07, 50.10it/s]\u001b[A\n",
      " 24%|██▍       | 114/478 [00:02<00:07, 50.09it/s]\u001b[A\n",
      " 25%|██▌       | 120/478 [00:02<00:07, 50.48it/s]\u001b[A\n",
      " 26%|██▋       | 126/478 [00:02<00:06, 50.76it/s]\u001b[A\n",
      " 28%|██▊       | 132/478 [00:02<00:06, 50.42it/s]\u001b[A\n",
      " 29%|██▉       | 138/478 [00:02<00:06, 50.58it/s]\u001b[A\n",
      " 30%|███       | 144/478 [00:02<00:06, 50.24it/s]\u001b[A\n",
      " 31%|███▏      | 150/478 [00:03<00:06, 50.32it/s]\u001b[A\n",
      " 33%|███▎      | 156/478 [00:03<00:06, 50.39it/s]\u001b[A\n",
      " 34%|███▍      | 162/478 [00:05<00:35,  8.81it/s]\u001b[A\n",
      " 35%|███▍      | 167/478 [00:05<00:26, 11.67it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation_acc:  0.3329841469376353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 36%|███▌      | 172/478 [00:05<00:20, 15.07it/s]\u001b[A\n",
      " 37%|███▋      | 177/478 [00:05<00:15, 19.05it/s]\u001b[A\n",
      " 38%|███▊      | 182/478 [00:05<00:12, 23.00it/s]\u001b[A\n",
      " 39%|███▉      | 187/478 [00:05<00:10, 26.79it/s]\u001b[A\n",
      " 40%|████      | 192/478 [00:05<00:09, 30.79it/s]\u001b[A\n",
      " 41%|████      | 197/478 [00:05<00:08, 34.55it/s]\u001b[A\n",
      " 42%|████▏     | 202/478 [00:06<00:07, 37.61it/s]\u001b[A\n",
      " 43%|████▎     | 207/478 [00:06<00:06, 39.77it/s]\u001b[A\n",
      " 44%|████▍     | 212/478 [00:06<00:06, 41.12it/s]\u001b[A\n",
      " 45%|████▌     | 217/478 [00:06<00:06, 42.83it/s]\u001b[A\n",
      " 46%|████▋     | 222/478 [00:06<00:05, 44.39it/s]\u001b[A\n",
      " 47%|████▋     | 227/478 [00:06<00:05, 44.95it/s]\u001b[A\n",
      " 49%|████▊     | 232/478 [00:06<00:05, 44.72it/s]\u001b[A\n",
      " 50%|████▉     | 237/478 [00:06<00:05, 45.40it/s]\u001b[A\n",
      " 51%|█████     | 242/478 [00:06<00:05, 46.28it/s]\u001b[A\n",
      " 52%|█████▏    | 247/478 [00:06<00:04, 47.07it/s]\u001b[A\n",
      " 53%|█████▎    | 252/478 [00:07<00:04, 47.65it/s]\u001b[A\n",
      " 54%|█████▍    | 257/478 [00:07<00:04, 47.25it/s]\u001b[A\n",
      " 55%|█████▍    | 262/478 [00:07<00:04, 46.21it/s]\u001b[A\n",
      " 56%|█████▌    | 267/478 [00:07<00:04, 46.62it/s]\u001b[A\n",
      " 57%|█████▋    | 272/478 [00:07<00:04, 46.99it/s]\u001b[A\n",
      " 58%|█████▊    | 277/478 [00:07<00:04, 47.79it/s]\u001b[A\n",
      " 59%|█████▉    | 282/478 [00:07<00:04, 47.68it/s]\u001b[A\n",
      " 60%|██████    | 287/478 [00:07<00:03, 48.16it/s]\u001b[A\n",
      " 61%|██████    | 292/478 [00:07<00:03, 47.38it/s]\u001b[A\n",
      " 62%|██████▏   | 297/478 [00:08<00:03, 46.40it/s]\u001b[A\n",
      " 63%|██████▎   | 302/478 [00:08<00:03, 45.72it/s]\u001b[A\n",
      " 64%|██████▍   | 307/478 [00:08<00:03, 45.27it/s]\u001b[A\n",
      " 65%|██████▌   | 312/478 [00:08<00:03, 44.99it/s]\u001b[A\n",
      " 66%|██████▋   | 317/478 [00:08<00:03, 45.65it/s]\u001b[A\n",
      " 67%|██████▋   | 322/478 [00:10<00:20,  7.46it/s]\u001b[A\n",
      " 68%|██████▊   | 327/478 [00:10<00:15,  9.91it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation_acc:  0.3674139255534604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 69%|██████▉   | 332/478 [00:10<00:11, 12.90it/s]\u001b[A\n",
      " 71%|███████   | 337/478 [00:10<00:08, 16.50it/s]\u001b[A\n",
      " 72%|███████▏  | 342/478 [00:10<00:06, 20.56it/s]\u001b[A\n",
      " 73%|███████▎  | 347/478 [00:11<00:05, 24.78it/s]\u001b[A\n",
      " 74%|███████▎  | 352/478 [00:11<00:04, 28.93it/s]\u001b[A\n",
      " 75%|███████▍  | 357/478 [00:11<00:03, 32.43it/s]\u001b[A\n",
      " 76%|███████▌  | 362/478 [00:11<00:03, 35.40it/s]\u001b[A\n",
      " 77%|███████▋  | 367/478 [00:11<00:02, 37.64it/s]\u001b[A\n",
      " 78%|███████▊  | 372/478 [00:11<00:02, 39.49it/s]\u001b[A\n",
      " 79%|███████▉  | 377/478 [00:11<00:02, 40.26it/s]\u001b[A\n",
      " 80%|███████▉  | 382/478 [00:11<00:02, 40.84it/s]\u001b[A\n",
      " 81%|████████  | 387/478 [00:11<00:02, 41.43it/s]\u001b[A\n",
      " 82%|████████▏ | 392/478 [00:12<00:02, 41.74it/s]\u001b[A\n",
      " 83%|████████▎ | 397/478 [00:12<00:01, 43.05it/s]\u001b[A\n",
      " 84%|████████▍ | 402/478 [00:12<00:01, 44.36it/s]\u001b[A\n",
      " 85%|████████▌ | 407/478 [00:12<00:01, 45.11it/s]\u001b[A\n",
      " 86%|████████▌ | 412/478 [00:12<00:01, 45.60it/s]\u001b[A\n",
      " 87%|████████▋ | 417/478 [00:12<00:01, 44.93it/s]\u001b[A\n",
      " 88%|████████▊ | 422/478 [00:12<00:01, 44.47it/s]\u001b[A\n",
      " 89%|████████▉ | 427/478 [00:12<00:01, 44.63it/s]\u001b[A\n",
      " 90%|█████████ | 432/478 [00:12<00:01, 44.33it/s]\u001b[A\n",
      " 91%|█████████▏| 437/478 [00:13<00:00, 44.85it/s]\u001b[A\n",
      " 92%|█████████▏| 442/478 [00:13<00:00, 45.56it/s]\u001b[A\n",
      " 94%|█████████▎| 447/478 [00:13<00:00, 45.70it/s]\u001b[A\n",
      " 95%|█████████▍| 452/478 [00:13<00:00, 44.59it/s]\u001b[A\n",
      " 96%|█████████▌| 457/478 [00:13<00:00, 43.94it/s]\u001b[A\n",
      " 97%|█████████▋| 462/478 [00:13<00:00, 44.01it/s]\u001b[A\n",
      " 98%|█████████▊| 467/478 [00:13<00:00, 44.39it/s]\u001b[A\n",
      " 99%|█████████▊| 472/478 [00:13<00:00, 44.42it/s]\u001b[A\n",
      "100%|██████████| 478/478 [00:15<00:00, 30.03it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation_acc:  0.3686709965779733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: train_loss: 0.059469761641317426, train_acc: 0.3227180669041134, vali_acc: 0.37202318597667433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/478 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 4/478 [00:00<00:11, 39.57it/s]\u001b[A\n",
      "  2%|▏         | 9/478 [00:00<00:11, 41.30it/s]\u001b[A\n",
      "  3%|▎         | 14/478 [00:00<00:10, 42.58it/s]\u001b[A\n",
      "  4%|▍         | 19/478 [00:00<00:10, 43.44it/s]\u001b[A\n",
      "  5%|▌         | 24/478 [00:00<00:10, 44.07it/s]\u001b[A\n",
      "  6%|▌         | 29/478 [00:00<00:10, 44.75it/s]\u001b[A\n",
      "  7%|▋         | 34/478 [00:00<00:09, 45.26it/s]\u001b[A\n",
      "  8%|▊         | 39/478 [00:00<00:09, 45.40it/s]\u001b[A\n",
      "  9%|▉         | 44/478 [00:00<00:09, 45.88it/s]\u001b[A\n",
      " 10%|█         | 49/478 [00:01<00:09, 45.83it/s]\u001b[A\n",
      " 11%|█▏        | 54/478 [00:01<00:09, 45.58it/s]\u001b[A\n",
      " 12%|█▏        | 59/478 [00:01<00:09, 45.60it/s]\u001b[A\n",
      " 13%|█▎        | 64/478 [00:01<00:09, 45.86it/s]\u001b[A\n",
      " 14%|█▍        | 69/478 [00:01<00:08, 46.21it/s]\u001b[A\n",
      " 15%|█▌        | 74/478 [00:01<00:08, 46.24it/s]\u001b[A\n",
      " 17%|█▋        | 79/478 [00:01<00:08, 46.38it/s]\u001b[A\n",
      " 18%|█▊        | 84/478 [00:01<00:08, 46.24it/s]\u001b[A\n",
      " 19%|█▊        | 89/478 [00:01<00:08, 46.42it/s]\u001b[A\n",
      " 20%|█▉        | 94/478 [00:02<00:08, 46.52it/s]\u001b[A\n",
      " 21%|██        | 99/478 [00:02<00:08, 46.43it/s]\u001b[A\n",
      " 22%|██▏       | 104/478 [00:02<00:08, 46.62it/s]\u001b[A\n",
      " 23%|██▎       | 109/478 [00:02<00:07, 46.67it/s]\u001b[A\n",
      " 24%|██▍       | 114/478 [00:02<00:07, 46.82it/s]\u001b[A\n",
      " 25%|██▍       | 119/478 [00:02<00:07, 46.79it/s]\u001b[A\n",
      " 26%|██▌       | 124/478 [00:02<00:07, 46.83it/s]\u001b[A\n",
      " 27%|██▋       | 129/478 [00:02<00:07, 46.12it/s]\u001b[A\n",
      " 28%|██▊       | 134/478 [00:02<00:07, 45.76it/s]\u001b[A\n",
      " 29%|██▉       | 139/478 [00:03<00:07, 45.88it/s]\u001b[A\n",
      " 30%|███       | 144/478 [00:03<00:07, 45.69it/s]\u001b[A\n",
      " 31%|███       | 149/478 [00:03<00:07, 45.58it/s]\u001b[A\n",
      " 32%|███▏      | 154/478 [00:03<00:07, 45.94it/s]\u001b[A\n",
      " 33%|███▎      | 159/478 [00:03<00:06, 45.88it/s]\u001b[A\n",
      " 34%|███▍      | 164/478 [00:05<00:43,  7.22it/s]\u001b[A\n",
      " 35%|███▌      | 169/478 [00:05<00:32,  9.63it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation_acc:  0.3845938962218032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 36%|███▋      | 174/478 [00:05<00:24, 12.61it/s]\u001b[A\n",
      " 37%|███▋      | 179/478 [00:05<00:18, 16.11it/s]\u001b[A\n",
      " 38%|███▊      | 184/478 [00:05<00:14, 19.75it/s]\u001b[A\n",
      " 40%|███▉      | 189/478 [00:06<00:12, 23.29it/s]\u001b[A\n",
      " 41%|████      | 194/478 [00:06<00:10, 27.27it/s]\u001b[A\n",
      " 42%|████▏     | 199/478 [00:06<00:09, 30.95it/s]\u001b[A\n",
      " 43%|████▎     | 204/478 [00:06<00:08, 34.16it/s]\u001b[A\n",
      " 44%|████▎     | 209/478 [00:06<00:07, 36.14it/s]\u001b[A\n",
      " 45%|████▍     | 214/478 [00:06<00:06, 38.25it/s]\u001b[A\n",
      " 46%|████▌     | 219/478 [00:06<00:06, 39.65it/s]\u001b[A\n",
      " 47%|████▋     | 224/478 [00:06<00:06, 41.18it/s]\u001b[A\n",
      " 48%|████▊     | 229/478 [00:06<00:05, 42.24it/s]\u001b[A\n",
      " 49%|████▉     | 234/478 [00:07<00:05, 43.15it/s]\u001b[A\n",
      " 50%|█████     | 239/478 [00:07<00:05, 44.25it/s]\u001b[A\n",
      " 51%|█████     | 244/478 [00:07<00:05, 44.70it/s]\u001b[A\n",
      " 52%|█████▏    | 249/478 [00:07<00:05, 45.09it/s]\u001b[A\n",
      " 53%|█████▎    | 254/478 [00:07<00:04, 45.60it/s]\u001b[A\n",
      " 54%|█████▍    | 259/478 [00:07<00:04, 45.83it/s]\u001b[A\n",
      " 55%|█████▌    | 264/478 [00:07<00:04, 45.89it/s]\u001b[A\n",
      " 56%|█████▋    | 269/478 [00:07<00:04, 45.81it/s]\u001b[A\n",
      " 57%|█████▋    | 274/478 [00:07<00:04, 45.90it/s]\u001b[A\n",
      " 58%|█████▊    | 279/478 [00:08<00:04, 45.60it/s]\u001b[A\n",
      " 59%|█████▉    | 284/478 [00:08<00:04, 46.01it/s]\u001b[A\n",
      " 60%|██████    | 289/478 [00:08<00:04, 45.90it/s]\u001b[A\n",
      " 62%|██████▏   | 294/478 [00:08<00:03, 46.15it/s]\u001b[A\n",
      " 63%|██████▎   | 299/478 [00:08<00:03, 46.24it/s]\u001b[A\n",
      " 64%|██████▎   | 304/478 [00:08<00:03, 46.20it/s]\u001b[A\n",
      " 65%|██████▍   | 309/478 [00:08<00:03, 46.15it/s]\u001b[A\n",
      " 66%|██████▌   | 314/478 [00:08<00:03, 46.08it/s]\u001b[A\n",
      " 67%|██████▋   | 319/478 [00:10<00:21,  7.38it/s]\u001b[A\n",
      " 68%|██████▊   | 324/478 [00:10<00:15,  9.85it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation_acc:  0.3907395767860884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 69%|██████▉   | 329/478 [00:11<00:11, 12.83it/s]\u001b[A\n",
      " 70%|██████▉   | 334/478 [00:11<00:08, 16.34it/s]\u001b[A\n",
      " 71%|███████   | 339/478 [00:11<00:06, 20.25it/s]\u001b[A\n",
      " 72%|███████▏  | 344/478 [00:11<00:05, 24.39it/s]\u001b[A\n",
      " 73%|███████▎  | 349/478 [00:11<00:04, 28.44it/s]\u001b[A\n",
      " 74%|███████▍  | 354/478 [00:11<00:03, 32.05it/s]\u001b[A\n",
      " 75%|███████▌  | 359/478 [00:11<00:03, 35.31it/s]\u001b[A\n",
      " 76%|███████▌  | 364/478 [00:11<00:03, 37.79it/s]\u001b[A\n",
      " 77%|███████▋  | 369/478 [00:11<00:02, 40.03it/s]\u001b[A\n",
      " 78%|███████▊  | 374/478 [00:12<00:02, 41.60it/s]\u001b[A\n",
      " 79%|███████▉  | 379/478 [00:12<00:02, 42.62it/s]\u001b[A\n",
      " 80%|████████  | 384/478 [00:12<00:02, 43.26it/s]\u001b[A\n",
      " 81%|████████▏ | 389/478 [00:12<00:02, 44.02it/s]\u001b[A\n",
      " 82%|████████▏ | 394/478 [00:12<00:01, 44.42it/s]\u001b[A\n",
      " 83%|████████▎ | 399/478 [00:12<00:01, 45.07it/s]\u001b[A\n",
      " 85%|████████▍ | 404/478 [00:12<00:01, 45.47it/s]\u001b[A\n",
      " 86%|████████▌ | 409/478 [00:12<00:01, 45.47it/s]\u001b[A\n",
      " 87%|████████▋ | 414/478 [00:12<00:01, 45.67it/s]\u001b[A\n",
      " 88%|████████▊ | 419/478 [00:13<00:01, 45.65it/s]\u001b[A\n",
      " 89%|████████▊ | 424/478 [00:13<00:01, 45.52it/s]\u001b[A\n",
      " 90%|████████▉ | 429/478 [00:13<00:01, 45.53it/s]\u001b[A\n",
      " 91%|█████████ | 434/478 [00:13<00:00, 45.54it/s]\u001b[A\n",
      " 92%|█████████▏| 439/478 [00:13<00:00, 45.48it/s]\u001b[A\n",
      " 93%|█████████▎| 444/478 [00:13<00:00, 45.80it/s]\u001b[A\n",
      " 94%|█████████▍| 449/478 [00:13<00:00, 45.49it/s]\u001b[A\n",
      " 95%|█████████▍| 454/478 [00:13<00:00, 45.07it/s]\u001b[A\n",
      " 96%|█████████▌| 459/478 [00:13<00:00, 45.14it/s]\u001b[A\n",
      " 97%|█████████▋| 464/478 [00:14<00:00, 44.91it/s]\u001b[A\n",
      " 98%|█████████▊| 469/478 [00:14<00:00, 44.17it/s]\u001b[A\n",
      "100%|██████████| 478/478 [00:16<00:00, 29.23it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation_acc:  0.3951393253718835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2: train_loss: 0.05015768307332129, train_acc: 0.3864795027585725, vali_acc: 0.3920664850897409\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    cuda = torch.cuda.is_available()\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    data_dict = np.load(args.data_path, allow_pickle=True)\n",
    "    \n",
    "    # TODO: to be commented\n",
    "    data_dict['tr_data'] = data_dict['tr_data'][:10]\n",
    "    data_dict['tr_data'] = data_dict['tr_data'][:10]\n",
    "    \n",
    "    # split train data and validation data\n",
    "    np.random.seed(seed=0)\n",
    "    indices = np.random.permutation(data_dict['tr_data'].shape[0])\n",
    "    train_x = data_dict['tr_data'][indices[:int(indices.shape[0]*0.9)],:,:].astype(\"float32\")\n",
    "    train_y = data_dict['tr_lbl'][indices[:int(indices.shape[0]*0.9)],:].astype(\"float32\")\n",
    "    vali_x = data_dict['tr_data'][indices[int(indices.shape[0]*0.9):],:,:].astype(\"float32\")\n",
    "    vali_y = data_dict['tr_lbl'][indices[int(indices.shape[0]*0.9):],:].astype(\"float32\")\n",
    "\n",
    "    \n",
    "    train_dataset = TimeSeriesChunkDataset(train_x, train_y, args.context)\n",
    "    train_dataloader = data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, pin_memory=True, num_workers=4)\n",
    "    vali_dataset = TimeSeriesChunkDataset(vali_x, vali_y, args.context)\n",
    "    vali_dataloader = data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, pin_memory=True, num_workers=4)\n",
    "    \n",
    "    model_args = {\n",
    "        'classifier': {\n",
    "            'layers_size': [args.context*2, 100, 100], \n",
    "            'dim_out': 50 if args.task == '3A' else 65\n",
    "        },\n",
    "        'generator':{\n",
    "            'transformer_layer': {},\n",
    "            'transformer': {}\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    \n",
    "    \n",
    "    source_classifier = SourceDomainClassifier(**model_args)\n",
    "    source_classifier.apply(init_weights)\n",
    "    \n",
    "    train(source_classifier, train_dataloader, vali_dataloader, args.lr, args.epochs, device)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformation.transformer_layer.self_attn.in_proj_weight tensor([[-0.0365, -0.8347],\n",
      "        [-0.1136, -0.7268],\n",
      "        [-0.8044, -0.5697],\n",
      "        [ 0.5512, -0.5657],\n",
      "        [ 0.5618, -0.2861],\n",
      "        [-0.3158,  0.6102]]) torch.float32\n",
      "transformation.transformer_layer.self_attn.in_proj_bias tensor([0., 0., 0., 0., 0., 0.]) torch.float32\n",
      "transformation.transformer_layer.self_attn.out_proj.weight tensor([[-1.0541, -0.2033],\n",
      "        [-0.3923, -1.0161]]) torch.float32\n",
      "transformation.transformer_layer.self_attn.out_proj.bias tensor([0., 0.]) torch.float32\n",
      "transformation.transformer_layer.linear1.weight tensor([[ 0.0526,  0.0169],\n",
      "        [-0.0167, -0.0424],\n",
      "        [ 0.0643, -0.0719],\n",
      "        ...,\n",
      "        [ 0.0023, -0.0527],\n",
      "        [-0.0460, -0.0076],\n",
      "        [-0.0416, -0.0403]]) torch.float32\n",
      "transformation.transformer_layer.linear1.bias tensor([0., 0., 0.,  ..., 0., 0., 0.]) torch.float32\n",
      "transformation.transformer_layer.linear2.weight tensor([[-0.0639,  0.0704, -0.0497,  ..., -0.0269,  0.0231, -0.0407],\n",
      "        [-0.0399,  0.0171,  0.0448,  ...,  0.0471,  0.0303,  0.0428]]) torch.float32\n",
      "transformation.transformer_layer.linear2.bias tensor([0., 0.]) torch.float32\n",
      "transformation.transformer_layer.norm1.weight tensor([1., 1.]) torch.float32\n",
      "transformation.transformer_layer.norm1.bias tensor([0., 0.]) torch.float32\n",
      "transformation.transformer_layer.norm2.weight tensor([1., 1.]) torch.float32\n",
      "transformation.transformer_layer.norm2.bias tensor([0., 0.]) torch.float32\n",
      "transformation.transformer.layers.0.self_attn.in_proj_weight tensor([[-0.0365, -0.8347],\n",
      "        [-0.1136, -0.7268],\n",
      "        [-0.8044, -0.5697],\n",
      "        [ 0.5512, -0.5657],\n",
      "        [ 0.5618, -0.2861],\n",
      "        [-0.3158,  0.6102]]) torch.float32\n",
      "transformation.transformer.layers.0.self_attn.in_proj_bias tensor([0., 0., 0., 0., 0., 0.]) torch.float32\n",
      "transformation.transformer.layers.0.self_attn.out_proj.weight tensor([[ 0.5098, -0.2092],\n",
      "        [-0.1309,  0.3730]]) torch.float32\n",
      "transformation.transformer.layers.0.self_attn.out_proj.bias tensor([0., 0.]) torch.float32\n",
      "transformation.transformer.layers.0.linear1.weight tensor([[ 0.0714,  0.0320],\n",
      "        [ 0.0740,  0.0682],\n",
      "        [ 0.0108, -0.0433],\n",
      "        ...,\n",
      "        [-0.0286,  0.0230],\n",
      "        [ 0.0265, -0.0059],\n",
      "        [-0.0293, -0.0310]]) torch.float32\n",
      "transformation.transformer.layers.0.linear1.bias tensor([0., 0., 0.,  ..., 0., 0., 0.]) torch.float32\n",
      "transformation.transformer.layers.0.linear2.weight tensor([[-0.0594,  0.0350,  0.0445,  ..., -0.0586,  0.0425,  0.0526],\n",
      "        [-0.0644,  0.0234, -0.0700,  ...,  0.0042,  0.0600,  0.0458]]) torch.float32\n",
      "transformation.transformer.layers.0.linear2.bias tensor([0., 0.]) torch.float32\n",
      "transformation.transformer.layers.0.norm1.weight tensor([1., 1.]) torch.float32\n",
      "transformation.transformer.layers.0.norm1.bias tensor([0., 0.]) torch.float32\n",
      "transformation.transformer.layers.0.norm2.weight tensor([1., 1.]) torch.float32\n",
      "transformation.transformer.layers.0.norm2.bias tensor([0., 0.]) torch.float32\n",
      "transformation.transformer.layers.1.self_attn.in_proj_weight tensor([[-0.0365, -0.8347],\n",
      "        [-0.1136, -0.7268],\n",
      "        [-0.8044, -0.5697],\n",
      "        [ 0.5512, -0.5657],\n",
      "        [ 0.5618, -0.2861],\n",
      "        [-0.3158,  0.6102]]) torch.float32\n",
      "transformation.transformer.layers.1.self_attn.in_proj_bias tensor([0., 0., 0., 0., 0., 0.]) torch.float32\n",
      "transformation.transformer.layers.1.self_attn.out_proj.weight tensor([[ 0.5128,  0.4925],\n",
      "        [-1.1705,  0.2353]]) torch.float32\n",
      "transformation.transformer.layers.1.self_attn.out_proj.bias tensor([0., 0.]) torch.float32\n",
      "transformation.transformer.layers.1.linear1.weight tensor([[-0.0410,  0.0712],\n",
      "        [ 0.0237, -0.0699],\n",
      "        [-0.0422,  0.0614],\n",
      "        ...,\n",
      "        [ 0.0406,  0.0053],\n",
      "        [-0.0353, -0.0605],\n",
      "        [-0.0689,  0.0506]]) torch.float32\n",
      "transformation.transformer.layers.1.linear1.bias tensor([0., 0., 0.,  ..., 0., 0., 0.]) torch.float32\n",
      "transformation.transformer.layers.1.linear2.weight tensor([[ 0.0162, -0.0190,  0.0033,  ..., -0.0434, -0.0761, -0.0014],\n",
      "        [-0.0700, -0.0065, -0.0759,  ..., -0.0079,  0.0637,  0.0068]]) torch.float32\n",
      "transformation.transformer.layers.1.linear2.bias tensor([0., 0.]) torch.float32\n",
      "transformation.transformer.layers.1.norm1.weight tensor([1., 1.]) torch.float32\n",
      "transformation.transformer.layers.1.norm1.bias tensor([0., 0.]) torch.float32\n",
      "transformation.transformer.layers.1.norm2.weight tensor([1., 1.]) torch.float32\n",
      "transformation.transformer.layers.1.norm2.bias tensor([0., 0.]) torch.float32\n",
      "transformation.transformer.layers.2.self_attn.in_proj_weight tensor([[-0.0365, -0.8347],\n",
      "        [-0.1136, -0.7268],\n",
      "        [-0.8044, -0.5697],\n",
      "        [ 0.5512, -0.5657],\n",
      "        [ 0.5618, -0.2861],\n",
      "        [-0.3158,  0.6102]]) torch.float32\n",
      "transformation.transformer.layers.2.self_attn.in_proj_bias tensor([0., 0., 0., 0., 0., 0.]) torch.float32\n",
      "transformation.transformer.layers.2.self_attn.out_proj.weight tensor([[-0.2457,  0.2031],\n",
      "        [ 0.6334,  1.1130]]) torch.float32\n",
      "transformation.transformer.layers.2.self_attn.out_proj.bias tensor([0., 0.]) torch.float32\n",
      "transformation.transformer.layers.2.linear1.weight tensor([[ 0.0100, -0.0123],\n",
      "        [-0.0235, -0.0023],\n",
      "        [-0.0558,  0.0070],\n",
      "        ...,\n",
      "        [ 0.0072,  0.0643],\n",
      "        [ 0.0173, -0.0672],\n",
      "        [ 0.0241, -0.0502]]) torch.float32\n",
      "transformation.transformer.layers.2.linear1.bias tensor([0., 0., 0.,  ..., 0., 0., 0.]) torch.float32\n",
      "transformation.transformer.layers.2.linear2.weight tensor([[ 0.0614, -0.0654, -0.0009,  ...,  0.0217,  0.0542, -0.0112],\n",
      "        [-0.0088, -0.0716,  0.0761,  ...,  0.0523, -0.0595, -0.0613]]) torch.float32\n",
      "transformation.transformer.layers.2.linear2.bias tensor([0., 0.]) torch.float32\n",
      "transformation.transformer.layers.2.norm1.weight tensor([1., 1.]) torch.float32\n",
      "transformation.transformer.layers.2.norm1.bias tensor([0., 0.]) torch.float32\n",
      "transformation.transformer.layers.2.norm2.weight tensor([1., 1.]) torch.float32\n",
      "transformation.transformer.layers.2.norm2.bias tensor([0., 0.]) torch.float32\n",
      "classifier.layers.0.weight tensor([[ 0.1429,  0.0733, -0.1988,  ..., -0.1152,  0.0961, -0.0418],\n",
      "        [ 0.1525, -0.1128,  0.2227,  ..., -0.1713, -0.1923, -0.1528],\n",
      "        [-0.0060,  0.0335,  0.1658,  ..., -0.0331,  0.0409,  0.1816],\n",
      "        ...,\n",
      "        [ 0.0924, -0.0367,  0.1536,  ...,  0.0869,  0.1197, -0.1350],\n",
      "        [-0.0720,  0.1811,  0.1396,  ...,  0.0237,  0.0279, -0.2043],\n",
      "        [-0.1435,  0.1185, -0.0675,  ..., -0.0402,  0.0125, -0.0606]]) torch.float32\n",
      "classifier.layers.0.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.]) torch.float32\n",
      "classifier.layers.1.weight tensor([[-0.1448,  0.1568,  0.0235,  ..., -0.1138, -0.1557, -0.0041],\n",
      "        [-0.1648, -0.0305,  0.1730,  ..., -0.0030,  0.0365, -0.1396],\n",
      "        [ 0.1307,  0.0724, -0.0923,  ...,  0.0023,  0.1712,  0.1038],\n",
      "        ...,\n",
      "        [-0.1188,  0.1653, -0.0493,  ...,  0.1180,  0.0068,  0.0815],\n",
      "        [-0.0732, -0.1027,  0.1081,  ...,  0.1380,  0.1327, -0.0572],\n",
      "        [-0.0068,  0.0895, -0.1151,  ..., -0.0719,  0.0146,  0.1470]]) torch.float32\n",
      "classifier.layers.1.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.]) torch.float32\n",
      "classifier.layers.2.weight tensor([[ 0.0879,  0.1698, -0.0364,  ...,  0.1086,  0.0545, -0.1242],\n",
      "        [ 0.1617,  0.0552,  0.0677,  ..., -0.0941, -0.1662, -0.1566],\n",
      "        [-0.1775,  0.0165, -0.0429,  ..., -0.0060, -0.0206,  0.0988],\n",
      "        ...,\n",
      "        [ 0.0928,  0.0639, -0.1140,  ...,  0.0869,  0.1549,  0.1410],\n",
      "        [ 0.0789,  0.1258, -0.0991,  ..., -0.1846,  0.1644,  0.1610],\n",
      "        [-0.0744,  0.1420, -0.1098,  ...,  0.1503,  0.0544,  0.0203]]) torch.float32\n",
      "classifier.layers.2.bias tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "for name, param in source_classifier.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print (name, param.data, param.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
