{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, inspect\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, parent_dir)\n",
    "sys.path.insert(0, os.path.join(parent_dir,'spring-break'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from martins.complex_transformer import ComplexTransformer\n",
    "from FNN import FNN\n",
    "from GAN import Generator, Discriminator\n",
    "from data_utils import *\n",
    "import argparse\n",
    "import logging\n",
    "import logging.handlers\n",
    "import pickle\n",
    "from centerloss import CenterLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JoinDataset(Dataset):\n",
    "    def __init__(self, source_x, source_y, target_x, target_y, random=False):\n",
    "        self.source_x = source_x\n",
    "        self.source_y = source_y\n",
    "        self.target_x = target_x\n",
    "        self.target_y = target_y\n",
    "        \n",
    "        self.source_len = self.source_y.shape[0]\n",
    "        self.target_len = self.target_y.shape[0]\n",
    "    \n",
    "        self.random = random\n",
    "    def __len__(self):\n",
    "        return self.target_len\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.random:\n",
    "            index_source = random.randrange(source_len)\n",
    "            index_target = random.randrange(target_len)\n",
    "        else:\n",
    "            index_source = index\n",
    "            index_target = index\n",
    "\n",
    "        return (self.source_x[index_source], self.source_y[index_source]), (self.target_x[index_target], self.target_y[index_target])\n",
    "    \n",
    "    \n",
    "class SingleDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "            self.x = x\n",
    "            self.y = y\n",
    "            self.len = self.y.shape[0]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "parser = argparse.ArgumentParser(description='JDA Time series adaptation')\n",
    "parser.add_argument(\"--data_path\", type=str, default=\"/projects/rsalakhugroup/complex/domain_adaptation\", help=\"dataset path\")\n",
    "parser.add_argument(\"--task\", type=str, help='3A or 3E')\n",
    "parser.add_argument('--batch_size', type=int, default=256, help='batch size')\n",
    "parser.add_argument('--epochs', type=int, default=50, help='number of epochs')\n",
    "parser.add_argument('--lr_gan', type=float, default=1e-3, help='learning rate for adversarial')\n",
    "parser.add_argument('--lr_centerloss', type=float, default=0.5, help='learning rate for centerloss')\n",
    "parser.add_argument('--lr_FNN', type=float, default=1e-3, help='learning rate for classification')\n",
    "parser.add_argument('--lr_encoder', type=float, default=1e-3, help='learning rate for classification')\n",
    "parser.add_argument('--lbl_percentage', type=float, default=0.2, help='percentage of which target data has label')\n",
    "parser.add_argument('--num_per_class', type=int, default=-1, help='number of sample per class when training local discriminator')\n",
    "parser.add_argument('--seed', type=int, default=0, help='manual seed')\n",
    "parser.add_argument('--save_path', type=str, help='where to store data')\n",
    "parser.add_argument('--model_save_period', type=int, default=2, help='period in which the model is saved')\n",
    "parser.add_argument('--sclass', type=float, default=0.7, help='source domain classification weight on loss function')\n",
    "parser.add_argument('--scent', type=float, default=0.01, help='source domain classification weight on centerloss')\n",
    "\n",
    "args = parser.parse_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # local only\n",
    "# class local_args:\n",
    "#     def __init__(self, **entries):\n",
    "#         self.__dict__.update(entries)\n",
    "        \n",
    "# args = local_args(**{\n",
    "#     'data_path': '/Users/stevenliu/time-series-adaption/time-series-domain-adaptation/data_unzip',\n",
    "#     'task': '3E',\n",
    "#     'num_class': 50,\n",
    "#     'batch_size': 100,\n",
    "#     'num_per_class': -1,\n",
    "#     'gap': 5,\n",
    "#     'lbl_percentage':0.2,\n",
    "#     'lr_gan': 1e-4,\n",
    "#     'lr_FNN': 1e-4,\n",
    "#     'lr_encoder': 1e-4,\n",
    "#     'epochs': 2,\n",
    "#     'clip_value': 0.01,\n",
    "#     'n_critic': 4,\n",
    "#     'sclass': 0.7,\n",
    "#     'scent': 1e-2,\n",
    "#     'seed': None,\n",
    "#     'save_path': '/Users/stevenliu/time-series-adaption/time-series-domain-adaptation/train_related',\n",
    "#     'model_save_period': 1,\n",
    "#     'lr_centerloss': 1e-3,\n",
    "#     'seed': 0\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# seed\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "cudnn.deterministic = True\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "args.task = '3Av2' if args.task == '3A' else '3E'\n",
    "num_class = 50 if args.task == \"3Av2\" else 65\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if args.num_per_class == -1:\n",
    "    args.num_per_class = math.ceil(args.batch_size / num_class)\n",
    "    \n",
    "model_sub_folder = '/stage2/task_%s_sclass_%f_scent_%f'%(args.task, args.sclass, args.scent)\n",
    "\n",
    "if not os.path.exists(args.save_path+model_sub_folder):\n",
    "    os.makedirs(args.save_path+model_sub_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "if os.path.isfile(args.save_path+model_sub_folder+ '/logfile.log'):\n",
    "    os.remove(args.save_path+model_sub_folder+ '/logfile.log')\n",
    "    \n",
    "file_log_handler = logging.FileHandler(args.save_path+model_sub_folder+ '/logfile.log')\n",
    "logger.addHandler(file_log_handler)\n",
    "\n",
    "stdout_log_handler = logging.StreamHandler(sys.stdout)\n",
    "logger.addHandler(stdout_log_handler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = np.load(args.data_path+'/processed_file_not_one_hot_%s.pkl'%args.task, allow_pickle=True)\n",
    "target_dict, (target_unlabel_x, target_unlabel_y),(target_label_x,target_label_y), target_len  = get_target_dict(args.data_path+'/processed_file_not_one_hot_%s.pkl'%args.task, num_class, args.lbl_percentage)\n",
    "source_dict, source_len = get_source_dict(args.data_path+'/processed_file_not_one_hot_%s.pkl'%args.task, num_class, data_len=target_len)\n",
    "join_dataset = JoinDataset(raw_data['tr_data'],raw_data['tr_lbl'],raw_data['te_data'],raw_data['te_lbl'], random=True)\n",
    "join_dataloader = DataLoader(join_dataset, batch_size=args.batch_size, shuffle=True, pin_memory=True, num_workers=4)\n",
    "\n",
    "source_dataset = SingleDataset(raw_data['tr_data'], raw_data['tr_lbl'])\n",
    "source_dataloader = DataLoader(source_dataset, batch_size=args.batch_size, shuffle=True, pin_memory=True, num_workers=4)\n",
    "target_lbl_dataset = SingleDataset(target_label_x, target_label_y)\n",
    "target_dataloader = DataLoader(target_lbl_dataset, batch_size=args.batch_size, shuffle=True, pin_memory=True, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# weight Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "    elif type(m) == nn.LayerNorm:\n",
    "        torch.nn.init.normal_(m.weight, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model creation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "seq_len = 10\n",
    "feature_dim = 160\n",
    "encoder = ComplexTransformer(layers=3,\n",
    "                               time_step=seq_len,\n",
    "                               input_dim=feature_dim,\n",
    "                               hidden_size=64,\n",
    "                               output_dim=64,\n",
    "                               num_heads=8,\n",
    "                               out_dropout=0.2,\n",
    "                               leaky_slope=0.2).to(device)\n",
    "\n",
    "CNet = FNN(d_in=64 * 2 * 1, d_h1=500, d_h2=500, d_out=num_class, dp=0.2).to(device)\n",
    "GNet = Generator(dim=64*2).to(device)\n",
    "\n",
    "criterion_classifier = nn.CrossEntropyLoss().to(device)\n",
    "criterion_centerloss = CenterLoss(num_classes=num_class, feat_dim=64 * 2 * 1, use_gpu=torch.cuda.is_available()).to(device)\n",
    "\n",
    "GNet.apply(weights_init)\n",
    "encoder.apply(weights_init)\n",
    "CNet.apply(weights_init)\n",
    "\n",
    "optimizerG = torch.optim.Adam(GNet.parameters(), lr=args.lr_gan)\n",
    "optimizerFNN = torch.optim.Adam(CNet.parameters(), lr=args.lr_FNN)\n",
    "optimizerEncoder = torch.optim.Adam(encoder.parameters(), lr=args.lr_encoder)\n",
    "optimizerCenterLoss = torch.optim.Adam(criterion_centerloss.parameters(), lr=args.lr_centerloss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_inference(encoder, CNet, x):\n",
    "    CNet.eval()\n",
    "    encoder.eval()\n",
    "    with torch.no_grad():\n",
    "        embedding = encoder_inference(encoder, x)\n",
    "        pred = CNet(embedding)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_inference(encoder, x):\n",
    "    real = x[:,:,0].reshape(x.size(0), seq_len, feature_dim).float()\n",
    "    imag = x[:,:,1].reshape(x.size(0), seq_len, feature_dim).float()\n",
    "    real, imag = encoder(real, imag)\n",
    "    return torch.cat((real[:,-1,:], imag[:,-1,:]), -1).reshape(x.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 142/142 [00:57<00:00,  2.46it/s]\n",
      "100%|██████████| 14/14 [00:05<00:00,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, update classifier: source acc: 0.017572; target acc: 0.008059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, assigned pesudo label with accuracy 0.016906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 142/142 [00:55<00:00,  2.54it/s]\n",
      "100%|██████████| 14/14 [00:05<00:00,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, update classifier: source acc: 0.016161; target acc: 0.021245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, assigned pesudo label with accuracy 0.014201\n"
     ]
    }
   ],
   "source": [
    "target_acc_label_ = []\n",
    "source_acc_ = []\n",
    "target_acc_unlabel_ = []\n",
    "\n",
    "\n",
    "logger.info('Started Training')\n",
    "for epoch in range(args.epochs):\n",
    "    # update classifier\n",
    "    # on source domain\n",
    "    CNet.train()\n",
    "    encoder.train()\n",
    "    GNet.train()\n",
    "    source_acc = 0.0\n",
    "    num_datas = 0.0\n",
    "    for batch_id, (source_x, source_y) in tqdm(enumerate(source_dataloader), total=len(source_dataloader)):\n",
    "        optimizerFNN.zero_grad()\n",
    "        optimizerEncoder.zero_grad()\n",
    "        optimizerCenterLoss.zero_grad()\n",
    "        source_x = source_x.to(device).float()\n",
    "        source_y = source_y.to(device)\n",
    "        num_datas += source_x.size(0)\n",
    "        source_x_embedding = encoder_inference(encoder, source_x)\n",
    "        pred = CNet(source_x_embedding)\n",
    "        source_acc += (pred.argmax(-1) == source_y).sum().item()\n",
    "        loss = (criterion_classifier(pred, source_y) +\n",
    "                criterion_centerloss(source_x_embedding, source_y) * args.scent) * args.sclass\n",
    "        loss.backward()\n",
    "        optimizerFNN.step()\n",
    "        optimizerCenterLoss.step()\n",
    "        optimizerEncoder.step()\n",
    "        \n",
    "    source_acc = source_acc / num_datas\n",
    "    source_acc_.append(source_acc)\n",
    "    \n",
    "    \n",
    "    # on target domain\n",
    "    target_acc = 0.0\n",
    "    num_datas = 0.0\n",
    "    CNet.train()\n",
    "    encoder.train()\n",
    "    GNet.train()\n",
    "    for batch_id, (target_x, target_y) in tqdm(enumerate(target_dataloader), total=len(target_dataloader)):\n",
    "        optimizerFNN.zero_grad()\n",
    "        optimizerG.zero_grad()\n",
    "        optimizerEncoder.zero_grad()\n",
    "        target_x = target_x.to(device).float()\n",
    "        target_y = target_y.to(device)\n",
    "        num_datas += target_x.size(0)\n",
    "        target_x_embedding = encoder_inference(encoder, target_x)\n",
    "        fake_source_embedding = GNet(target_x_embedding)\n",
    "        pred = CNet(fake_source_embedding)\n",
    "        target_acc += (pred.argmax(-1) == target_y).sum().item()\n",
    "        loss = criterion_classifier(pred, target_y)\n",
    "        loss.backward()\n",
    "        optimizerFNN.step()\n",
    "        optimizerG.step()\n",
    "        optimizerEncoder.step()\n",
    "    \n",
    "    target_acc = target_acc / num_datas\n",
    "    target_acc_label_.append(target_acc)\n",
    "    \n",
    "    correct_target = 0.0\n",
    "    num_datas = 0.0\n",
    "    CNet.eval()\n",
    "    encoder.eval()\n",
    "    GNet.eval()\n",
    "    for batch in range(math.ceil(target_unlabel_x.shape[0]/args.batch_size)):\n",
    "        target_unlabel_x_batch = torch.Tensor(target_unlabel_x[batch*args.batch_size:(batch+1)*args.batch_size]).to(device).float()\n",
    "        target_unlabel_y_batch = torch.Tensor(target_unlabel_y[batch*args.batch_size:(batch+1)*args.batch_size]).to(device)\n",
    "        num_datas += target_unlabel_x_batch.shape[0]\n",
    "        target_unlabel_x_embedding = encoder_inference(encoder, target_unlabel_x_batch)\n",
    "        fake_source_embedding = GNet(target_unlabel_x_embedding)\n",
    "        pred = CNet(fake_source_embedding)\n",
    "        correct_target += (pred.argmax(-1) == target_unlabel_y_batch).sum().item()\n",
    "        \n",
    "    target_unlabel_acc = correct_target/num_datas\n",
    "    target_acc_unlabel_.append(target_unlabel_acc)\n",
    "    \n",
    "    if epoch % args.model_save_period == 0:\n",
    "        torch.save(GNet.state_dict(), args.save_path+model_sub_folder+ '/GNet_%i.t7'%(epoch+1))\n",
    "        torch.save(encoder.state_dict(), args.save_path+model_sub_folder+ '/encoder_%i.t7'%(epoch+1))\n",
    "        torch.save(CNet.state_dict(), args.save_path+model_sub_folder+ '/CNet_%i.t7'%(epoch+1))\n",
    "        torch.save(criterion_centerloss.state_dict(), args.save_path+model_sub_folder+ '/centerloss_%i.t7'%(epoch+1))\n",
    "    logger.info('Epochs %i: source acc: %f; target labled acc: %f; target unlabeled acc: %f'%(epoch+1, source_acc, target_acc, target_unlabel_acc))\n",
    "    \n",
    "    np.save(args.save_path+model_sub_folder+'/target_acc_label_.npy',target_acc_label_)\n",
    "    np.save(args.save_path+model_sub_folder+'/source_acc_.npy',source_acc_)\n",
    "    np.save(args.save_path+model_sub_folder+'/target_acc_unlabel_.npy',target_acc_unlabel_)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " target unlabeled acc: 0.614539\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_PATH = '/Users/stevenliu/Downloads/stage2_weights'\n",
    "CNet.load_state_dict(torch.load(model_PATH+'/CNet_146.t7', map_location=device))\n",
    "encoder.load_state_dict(torch.load(model_PATH+'/encoder_146.t7', map_location=device))\n",
    "GNet.load_state_dict(torch.load(model_PATH+'/GNet_146.t7', map_location=device))\n",
    "\n",
    "target_acc_label_ = []\n",
    "source_acc_ = []\n",
    "target_acc_unlabel_ = []\n",
    "\n",
    "correct_target = 0.0\n",
    "num_datas = 0.0\n",
    "CNet.eval()\n",
    "encoder.eval()\n",
    "GNet.eval()\n",
    "for batch in range(math.ceil(target_unlabel_x.shape[0]/args.batch_size)):\n",
    "    target_unlabel_x_batch = torch.Tensor(target_unlabel_x[batch*args.batch_size:(batch+1)*args.batch_size]).to(device).float()\n",
    "    target_unlabel_y_batch = torch.Tensor(target_unlabel_y[batch*args.batch_size:(batch+1)*args.batch_size]).to(device)\n",
    "    num_datas += target_unlabel_x_batch.shape[0]\n",
    "    target_unlabel_x_embedding = encoder_inference(encoder, target_unlabel_x_batch)\n",
    "    fake_source_embedding = GNet(target_unlabel_x_embedding)\n",
    "    pred = CNet(fake_source_embedding)\n",
    "    correct_target += (pred.argmax(-1) == target_unlabel_y_batch).sum().item()\n",
    "\n",
    "target_unlabel_acc = correct_target/num_datas\n",
    "target_acc_unlabel_.append(target_unlabel_acc)\n",
    "logger.info(' target unlabeled acc: %f'%( target_unlabel_acc))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
