{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, inspect\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, parent_dir)\n",
    "sys.path.insert(0, os.path.join(parent_dir,'spring-break'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from shutil import copyfile\n",
    "import copy\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from martins.complex_transformer import ComplexTransformer\n",
    "from FNN import FNN\n",
    "from FNNLinear import FNNLinear\n",
    "from FNNSeparated import FNNSeparated\n",
    "from powerfulGAN import Generator, Discriminator\n",
    "from data_utils import *\n",
    "import argparse\n",
    "import logging\n",
    "import logging.handlers\n",
    "import pickle\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import grad as torch_grad\n",
    "from centerloss import CenterLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JoinDataset(Dataset):\n",
    "    def __init__(self, source_x, source_y, target_x, target_y, random=False):\n",
    "        self.source_x = source_x\n",
    "        self.source_y = source_y\n",
    "        self.target_x = target_x\n",
    "        self.target_y = target_y\n",
    "        \n",
    "        self.source_len = self.source_y.shape[0]\n",
    "        self.target_len = self.target_y.shape[0]\n",
    "    \n",
    "        self.random = random\n",
    "    def __len__(self):\n",
    "        return self.target_len\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.random:\n",
    "            index_source = random.randrange(self.source_len)\n",
    "            index_target = random.randrange(self.target_len)\n",
    "        else:\n",
    "            index_source = index\n",
    "            index_target = index\n",
    "\n",
    "        return (self.source_x[index_source], self.source_y[index_source]), (self.target_x[index_target], self.target_y[index_target])\n",
    "    \n",
    "    \n",
    "class SingleDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.len = self.y.shape[0]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SimpleMLP1(nn.Sequential):\n",
    "    def __init__(self):\n",
    "        super(SimpleMLP1, self).__init__(\n",
    "            nn.Linear(3200,1600),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1600,800),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(800,800),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(800,400),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(400,400),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(400,400),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(400,200),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(200,200),\n",
    "            nn.ELU(),\n",
    "        )\n",
    "        \n",
    "class SimpleMLP2(nn.Sequential):\n",
    "    def __init__(self):\n",
    "        super(SimpleMLP2, self).__init__(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(200,num_class),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--data_path DATA_PATH] [--task TASK] [--batch_size BATCH_SIZE] [--epochs EPOCHS] [--lr_gan LR_GAN]\n",
      "                             [--lr_FNN LR_FNN] [--lr_encoder LR_ENCODER] [--n_critic N_CRITIC] [--target_lbl_percentage TARGET_LBL_PERCENTAGE]\n",
      "                             [--source_lbl_percentage SOURCE_LBL_PERCENTAGE] [--num_per_class NUM_PER_CLASS] [--seed SEED]\n",
      "                             [--save_path SAVE_PATH] [--model_save_period MODEL_SAVE_PERIOD] [--gpweight GPWEIGHT] [--sclass SCLASS]\n",
      "                             [--dlocal DLOCAL] [--dglobal DGLOBAL] [--GANweights GANWEIGHTS] [--isglobal ISGLOBAL]\n",
      "                             [--lr_centerloss LR_CENTERLOSS] [--pure_random PURE_RANDOM]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/tianqinl/.local/share/jupyter/runtime/kernel-dea00d31-da8d-4ae5-9196-8803fc65f981.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tianqinl/anaconda3/envs/russ-local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "parser = argparse.ArgumentParser(description='JDA Time series adaptation')\n",
    "parser.add_argument(\"--data_path\", type=str, default=\"../data_unzip/\", help=\"dataset path\")\n",
    "parser.add_argument(\"--task\", type=str, help='3A or 3E')\n",
    "parser.add_argument('--batch_size', type=int, default=400, help='batch size')\n",
    "parser.add_argument('--epochs', type=int, default=50, help='number of epochs')\n",
    "\n",
    "parser.add_argument('--lr_gan_G', type=float, default=1e-3, help='learning rate for adversarial generator')\n",
    "parser.add_argument('--lr_gan_D', type=float, default=1e-3 / 6, help='learning rate for adversarial discrimitor')\n",
    "\n",
    "parser.add_argument('--lr_FNN', type=float, default=1e-3, help='learning rate for classification')\n",
    "parser.add_argument('--lr_encoder', type=float, default=1e-3, help='learning rate for classification')\n",
    "parser.add_argument('--n_critic', type=float, default=0.16, help='gap: Generator train GAP times, discriminator train once')\n",
    "parser.add_argument('--target_lbl_percentage', type=float, default=0.7, help='percentage of target labeled data')\n",
    "parser.add_argument('--source_lbl_percentage', type=float, default=0.7, help='percentage of source labeled data')\n",
    "parser.add_argument('--num_per_class', type=int, default=2, help='number of sample per class when training local discriminator')\n",
    "parser.add_argument('--seed', type=int, help='manual seed')\n",
    "parser.add_argument('--save_path', type=str, default=\"../train_related/\", help='where to store data')\n",
    "parser.add_argument('--model_save_period', type=int, default=2, help='period in which the model is saved')\n",
    "parser.add_argument('--gpweight', type=float, default=10, help='clip_value for WGAN')\n",
    "parser.add_argument('--sclass', type=float, default=0.7, help='source domain classification weight on loss function')\n",
    "parser.add_argument('--dlocal', type=float, default=0.01, help='local GAN weight on loss function')\n",
    "parser.add_argument('--dglobal', type=float, default=0.01, help='global GAN weight on loss function')\n",
    "parser.add_argument('--GANweights', type=int, default=-1, help='pretrained GAN weight')\n",
    "parser.add_argument('--isglobal', type=int, default=0, help='if using global DNet')\n",
    "parser.add_argument('--islocal', type=int, default=1, help='if using local DNet')\n",
    "parser.add_argument('--lr_centerloss', type=float, default=1e-3, help='center loss weight')\n",
    "parser.add_argument('--pure_random', type=int, default=1, help='Pure random for n_critic')\n",
    "\n",
    "\n",
    "args = parser.parse_args()\n",
    "args.isglobal = True if args.isglobal == 1 else False\n",
    "args.islocal = True if args.islocal == 1 else False\n",
    "args.pure_random = True if args.pure_random == 1 else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # local only\n",
    "# class local_args:\n",
    "#     def __init__(self, **entries):\n",
    "#         self.__dict__.update(entries)\n",
    "        \n",
    "# args = local_args(**{\n",
    "#     'data_path': '/home/tianqinl/Code/time-series-domain-adaptation/data_unzip',\n",
    "#     'task': '3E',\n",
    "#     'num_class': 50,\n",
    "#     'batch_size': 100,\n",
    "#     'num_per_class': 2,\n",
    "#     'gap': 5,\n",
    "#     'lbl_percentage':0.2,\n",
    "#     'lr_gan': 1e-4,\n",
    "#     'lr_FNN': 1e-4,\n",
    "#     'lr_encoder': 1e-4,\n",
    "#     'epochs': 2,\n",
    "#     'clip_value': 0.01,\n",
    "#     'n_critic': 0.16,\n",
    "#     'save_path': '/home/tianqinl/Code/time-series-domain-adaptation/train_related/',\n",
    "#     'target_lbl_percentage': 0.7,\n",
    "#     'source_lbl_percentage': 0.7,\n",
    "#     'lr_centerloss': 1e-3,\n",
    "#     'sclass': 0.7,\n",
    "#     'isglobal': True,\n",
    "#     'gpweight': 10,\n",
    "#     'dlocal': 1e-2,\n",
    "#     'model_save_period': 2,\n",
    "#     'pure_random': True,\n",
    "#     'dglobal': 0.01,\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "args.task = '3Av2' if args.task == '3A' else '3E'\n",
    "num_class = 50 if args.task == \"3Av2\" else 65\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if args.num_per_class == -1:\n",
    "    args.num_per_class = math.ceil(args.batch_size / num_class)\n",
    "    \n",
    "model_sub_folder = 'Linear_GAN/SimpleMLP_task_%s_gpweight_%f_dlocal_%f_critic_%f_rand_%i_sclass_%f_global_%i_local_%i'%(args.task, args.gpweight, args.dlocal, args.n_critic, args.pure_random, args.sclass, args.isglobal, args.islocal)\n",
    "\n",
    "save_folder = os.path.join(args.save_path, model_sub_folder)\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_path: /home/tianqinl/Code/time-series-domain-adaptation/data_unzip\n",
      "task: 3E\n",
      "num_class: 50\n",
      "batch_size: 100\n",
      "num_per_class: 2\n",
      "gap: 5\n",
      "lbl_percentage: 0.2\n",
      "lr_gan: 0.0001\n",
      "lr_FNN: 0.0001\n",
      "lr_encoder: 0.0001\n",
      "epochs: 2\n",
      "clip_value: 0.01\n",
      "n_critic: 0.16\n",
      "save_path: /home/tianqinl/Code/time-series-domain-adaptation/train_related/\n",
      "target_lbl_percentage: 0.7\n",
      "source_lbl_percentage: 0.7\n",
      "lr_centerloss: 0.001\n",
      "sclass: 0.7\n",
      "isglobal: True\n",
      "gpweight: 10\n",
      "dlocal: 0.01\n",
      "model_save_period: 2\n",
      "pure_random: True\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "if os.path.isfile(os.path.join(save_folder, 'logfile.log')):\n",
    "    os.remove(os.path.join(save_folder, 'logfile.log'))\n",
    "\n",
    "file_log_handler = logging.FileHandler(os.path.join(save_folder, 'logfile.log'))\n",
    "logger.addHandler(file_log_handler)\n",
    "\n",
    "stdout_log_handler = logging.StreamHandler(sys.stdout)\n",
    "logger.addHandler(stdout_log_handler)\n",
    "\n",
    "attrs = vars(args)\n",
    "for item in attrs.items():\n",
    "    logger.info(\"%s: %s\"%item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copyfile(python_file_name, os.path.join(save_folder, 'executed.py'))\n",
    "commands = ['python']\n",
    "commands.extend(sys.argv)\n",
    "with open(os.path.join(save_folder, 'command.log'), 'w') as f:\n",
    "    f.write(' '.join(commands))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_target_x_filename = '/processed_file_not_one_hot_%s_%1.1f_target_known_label_x.npy'%(args.task, args.target_lbl_percentage)\n",
    "labeled_target_y_filename = '/processed_file_not_one_hot_%s_%1.1f_target_known_label_y.npy'%(args.task, args.target_lbl_percentage)\n",
    "unlabeled_target_x_filename = '/processed_file_not_one_hot_%s_%1.1f_target_unknown_label_x.npy'%(args.task, args.target_lbl_percentage)\n",
    "unlabeled_target_y_filename = '/processed_file_not_one_hot_%s_%1.1f_target_unknown_label_y.npy'%(args.task, args.target_lbl_percentage)\n",
    "labeled_target_x = np.load(args.data_path+labeled_target_x_filename)\n",
    "labeled_target_y = np.load(args.data_path+labeled_target_y_filename)\n",
    "unlabeled_target_x = np.load(args.data_path+unlabeled_target_x_filename)\n",
    "unlabeled_target_y = np.load(args.data_path+unlabeled_target_y_filename)\n",
    "labeled_target_dataset = SingleDataset(labeled_target_x, labeled_target_y)\n",
    "unlabled_target_dataset = SingleDataset(unlabeled_target_x, unlabeled_target_y)\n",
    "labeled_target_dataloader = DataLoader(labeled_target_dataset, batch_size=args.batch_size, shuffle=True, pin_memory=True, num_workers=4)\n",
    "unlabeled_target_dataloader = DataLoader(unlabled_target_dataset, batch_size=args.batch_size, shuffle=False, pin_memory=True, num_workers=4)\n",
    "\n",
    "label_target_len = labeled_target_x.shape[0]\n",
    "\n",
    "labeled_source_x_filename = '/processed_file_not_one_hot_%s_%1.1f_source_known_label_x.npy'%(args.task, args.source_lbl_percentage)\n",
    "labeled_source_y_filename = '/processed_file_not_one_hot_%s_%1.1f_source_known_label_y.npy'%(args.task, args.source_lbl_percentage)\n",
    "unlabeled_source_x_filename = '/processed_file_not_one_hot_%s_%1.1f_source_unknown_label_x.npy'%(args.task, args.source_lbl_percentage)\n",
    "unlabeled_source_y_filename = '/processed_file_not_one_hot_%s_%1.1f_source_unknown_label_y.npy'%(args.task, args.source_lbl_percentage)\n",
    "labeled_source_x = np.load(args.data_path+labeled_source_x_filename)\n",
    "labeled_source_y = np.load(args.data_path+labeled_source_y_filename)\n",
    "unlabeled_source_x = np.load(args.data_path+unlabeled_source_x_filename)\n",
    "unlabeled_source_y = np.load(args.data_path+unlabeled_source_y_filename)\n",
    "labeled_source_dataset = SingleDataset(labeled_source_x, labeled_source_y)\n",
    "unlabled_source_dataset = SingleDataset(unlabeled_source_x, unlabeled_source_y)\n",
    "labeled_source_dataloader = DataLoader(labeled_source_dataset, batch_size=args.batch_size, shuffle=True, pin_memory=True, num_workers=4)\n",
    "unlabeled_source_dataloader = DataLoader(unlabled_source_dataset, batch_size=args.batch_size, shuffle=False, pin_memory=True, num_workers=4)\n",
    "\n",
    "\n",
    "join_dataset = JoinDataset(labeled_source_x, labeled_source_y, labeled_target_x, labeled_target_y, random=True)\n",
    "join_dataloader = DataLoader(join_dataset, batch_size=args.batch_size, shuffle=True, pin_memory=True, num_workers=4)\n",
    "\n",
    "source_labeled_dict = get_class_data_dict(labeled_source_x, labeled_source_y, num_class)\n",
    "target_labeled_dict = get_class_data_dict(labeled_target_x, labeled_target_y, num_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# weight Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "    elif type(m) == nn.LayerNorm:\n",
    "        torch.nn.init.normal_(m.weight, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "seq_len = 10\n",
    "feature_dim = 160\n",
    "\n",
    "encoder = SimpleMLP1().to(device)\n",
    "CNet = SimpleMLP2().to(device)\n",
    "\n",
    "\n",
    "DNet_global = Discriminator(feature_dim=200, d_out=1).to(device)\n",
    "DNet_local = Discriminator(feature_dim=200, d_out=num_class).to(device)\n",
    "GNet = Generator(dim=200).to(device)\n",
    "\n",
    "\n",
    "criterion_classifier = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "\n",
    "DNet_global.apply(weights_init)\n",
    "DNet_local.apply(weights_init)\n",
    "GNet.apply(weights_init)\n",
    "encoder.apply(weights_init)\n",
    "CNet.apply(weights_init)\n",
    "optimizerD_global = torch.optim.Adam(DNet_global.parameters(), lr=args.lr_gan_D)\n",
    "optimizerD_local = torch.optim.Adam(DNet_local.parameters(), lr=args.lr_gan_D)\n",
    "optimizerG = torch.optim.Adam(GNet.parameters(), lr=args.lr_gan_G)\n",
    "optimizerCNet = torch.optim.Adam(CNet.parameters(), lr=args.lr_FNN)\n",
    "optimizerEncoder = torch.optim.Adam(encoder.parameters(), lr=args.lr_encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_inference(encoder, CNet, x):\n",
    "    CNet.eval()\n",
    "    encoder.eval()\n",
    "    with torch.no_grad():\n",
    "        embedding = encoder_inference(encoder, x)\n",
    "        pred = CNet(embedding)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_inference(encoder, encoder_MLP, x):\n",
    "    real = x[:,:,0].reshape(x.size(0), seq_len, feature_dim).float()\n",
    "    imag = x[:,:,1].reshape(x.size(0), seq_len, feature_dim).float()\n",
    "    real, imag = encoder(real, imag)\n",
    "    cat_embedding = torch.cat((real[:,-1,:], imag[:,-1,:]), -1).reshape(x.shape[0], -1)\n",
    "    cat_embedding = encoder_MLP(cat_embedding)\n",
    "    return cat_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gradient_penalty(real_data, generated_data, DNet, mask, num_class, device, args):\n",
    "    batch_size = real_data.size()[0]\n",
    "\n",
    "    # Calculate interpolation\n",
    "    alpha = torch.rand(batch_size, 1)\n",
    "    alpha = alpha.expand_as(real_data)\n",
    "    alpha = alpha.to(device)\n",
    "    interpolated = alpha * real_data.data + (1 - alpha) * generated_data.data\n",
    "    interpolated = Variable(interpolated, requires_grad=True)\n",
    "    interpolated = interpolated.to(device)\n",
    "\n",
    "    # Calculate probability of interpolated examples\n",
    "    prob_interpolated = DNet(interpolated, mask)\n",
    "\n",
    "    # Calculate gradients of probabilities with respect to examples\n",
    "    gradients = torch_grad(outputs=prob_interpolated, inputs=interpolated,\n",
    "                           grad_outputs=torch.ones(prob_interpolated.size()).to(device),\n",
    "                           create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "    # Gradients have shape (batch_size, num_channels, img_width, img_height),\n",
    "    # so flatten to easily take norm per example in batch\n",
    "    gradients = gradients.view(batch_size, -1)\n",
    "\n",
    "    # Derivatives of the gradient close to 0 can cause problems because of\n",
    "    # the square root, so manually calculate norm and add epsilon\n",
    "    gradients_norm = torch.sqrt(torch.sum(gradients ** 2, dim=1, keepdim=True) + 1e-12)\n",
    "\n",
    "    gradients_norm = gradients_norm * mask\n",
    "    # Return gradient penalty\n",
    "    return args.gpweight * ((gradients_norm - 1) ** 2).mean(dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gradient_penalty_global(real_data, generated_data, DNet, num_class, device, args):\n",
    "        batch_size = real_data.size()[0]\n",
    "\n",
    "        # Calculate interpolation\n",
    "        alpha = torch.rand(batch_size, 1)\n",
    "        alpha = alpha.expand_as(real_data)\n",
    "        alpha = alpha.to(device)\n",
    "        interpolated = alpha * real_data.data + (1 - alpha) * generated_data.data\n",
    "        interpolated = Variable(interpolated, requires_grad=True)\n",
    "        interpolated = interpolated.to(device)\n",
    "\n",
    "        # Calculate probability of interpolated examples\n",
    "        prob_interpolated = DNet(interpolated, 1)\n",
    "\n",
    "        # Calculate gradients of probabilities with respect to examples\n",
    "        gradients = torch_grad(outputs=prob_interpolated, inputs=interpolated,\n",
    "                               grad_outputs=torch.ones(prob_interpolated.size()).to(device),\n",
    "                               create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "        # Gradients have shape (batch_size, num_channels, img_width, img_height),\n",
    "        # so flatten to easily take norm per example in batch\n",
    "        gradients = gradients.view(batch_size, -1)\n",
    "\n",
    "        # Derivatives of the gradient close to 0 can cause problems because of\n",
    "        # the square root, so manually calculate norm and add epsilon\n",
    "        gradients_norm = torch.sqrt(torch.sum(gradients ** 2, dim=1) + 1e-12)\n",
    "\n",
    "        # Return gradient penalty\n",
    "        return args.gpweight * ((gradients_norm - 1) ** 2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:00<00:00, 166.25it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 118.43it/s]\n",
      "100%|██████████| 43/43 [00:00<00:00, 451.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, update classifier: source acc: 0.120243; source unlbl acc: 0.156177; target acc: 0.030162; target unlabel acc: 0.126807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 50/50 [00:00<00:00, 106.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Global Discrimator Updates: Loss D_global: 0.588919, Loss G: -2.511856; update_ratio: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 50/50 [00:00<00:00, 92.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Local Discrimator Updates: Loss D_local: 56.828399, Loss G: 0.004665; update_ratio: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 99/99 [00:00<00:00, 163.85it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 121.72it/s]\n",
      "100%|██████████| 43/43 [00:00<00:00, 411.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, update classifier: source acc: 0.152632; source unlbl acc: 0.182751; target acc: 0.031781; target unlabel acc: 0.125408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 106.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Global Discrimator Updates: Loss D_global: 0.415205, Loss G: -2.170705; update_ratio: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 50/50 [00:00<00:00, 84.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Local Discrimator Updates: Loss D_local: 80.548253, Loss G: -0.533958; update_ratio: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "target_acc_label_ = []\n",
    "source_acc_ = []\n",
    "source_acc_unlabel_ = []\n",
    "target_acc_unlabel_ = []\n",
    "error_D_global = []\n",
    "error_G_global = []\n",
    "error_D_local = []\n",
    "error_G_local = []\n",
    "\n",
    "\n",
    "# # pre-trained\n",
    "# model_PATH = '../train_related/spring_break/stage2/task_3E_SClassWeight_0.700000_old'\n",
    "# CNet.load_state_dict(torch.load(model_PATH+'/CNet_pre_trained.t7', map_location=device))\n",
    "# encoder.load_state_dict(torch.load(model_PATH+'/encoder_pre_trained.t7', map_location=device))\n",
    "# GNet.load_state_dict(torch.load(model_PATH+'/GNet_pre_trained.t7', map_location=device))\n",
    "# print('Model Loaded!')\n",
    "\n",
    "# if args.GANweights !='-1':\n",
    "#     GAN_PATH = '../train_related/spring_break/stage3_local_gp_no_class/task_3E_gpweight_20.000000_dlocal_0.010000_critic_0.160000_sclass_0.700000'\n",
    "#     GNet.load_state_dict(torch.load(GAN_PATH+'/GNet_%i.t7'%args.GANweights, map_location=device))\n",
    "#     DNet_local.load_state_dict(torch.load(GAN_PATH+'/DNet_local_%i.t7'%args.GANweights, map_location=device))\n",
    "\n",
    "print('Started training')\n",
    "for epoch in range(args.epochs):\n",
    "    # update classifier\n",
    "    # on source domain\n",
    "    CNet.train()\n",
    "    encoder.train()\n",
    "    GNet.train()\n",
    "    source_acc = 0.0\n",
    "    num_datas = 0.0\n",
    "    for batch_id, (source_x, source_y) in tqdm(enumerate(labeled_source_dataloader), total=len(labeled_source_dataloader)):\n",
    "        optimizerCNet.zero_grad()\n",
    "        optimizerEncoder.zero_grad()\n",
    "        source_x = source_x.to(device).view(-1, 3200).float()\n",
    "        source_y = source_y.to(device)\n",
    "        num_datas += source_x.size(0)\n",
    "        source_x_embedding = encoder(source_x)\n",
    "        pred = CNet(source_x_embedding)\n",
    "        source_acc += (pred.argmax(-1) == source_y).sum().item()\n",
    "        loss = criterion_classifier(pred, source_y) * args.sclass\n",
    "        loss.backward()\n",
    "        optimizerCNet.step()\n",
    "        optimizerEncoder.step()\n",
    "        \n",
    "\n",
    "        \n",
    "    source_acc = source_acc / num_datas\n",
    "    source_acc_.append(source_acc)\n",
    "    \n",
    "    \n",
    "    # on target domain\n",
    "    target_acc = 0.0\n",
    "    num_datas = 0.0\n",
    "    CNet.train()\n",
    "    encoder.train()\n",
    "    GNet.train()\n",
    "    for batch_id, (target_x, target_y) in tqdm(enumerate(labeled_target_dataloader), total=len(labeled_target_dataloader)):\n",
    "        optimizerCNet.zero_grad()\n",
    "        optimizerG.zero_grad()\n",
    "        optimizerEncoder.zero_grad()\n",
    "        target_x = target_x.to(device).view(-1, 3200).float()\n",
    "        target_y = target_y.to(device)\n",
    "        num_datas += target_x.size(0)\n",
    "        target_x_embedding = encoder(target_x)\n",
    "        fake_source_embedding = GNet(target_x_embedding)\n",
    "        pred = CNet(fake_source_embedding)\n",
    "        target_acc += (pred.argmax(-1) == target_y).sum().item()\n",
    "        loss = criterion_classifier(pred, target_y)\n",
    "        loss.backward()\n",
    "        optimizerCNet.step()\n",
    "        optimizerG.step()\n",
    "        optimizerEncoder.step()\n",
    "        \n",
    "\n",
    "    \n",
    "    target_acc = target_acc / num_datas\n",
    "    target_acc_label_.append(target_acc)\n",
    "    \n",
    "    # eval\n",
    "    # source_domain\n",
    "    source_acc_unlabel = 0.0\n",
    "    num_datas = 0.0\n",
    "    CNet.eval()\n",
    "    encoder.eval()\n",
    "    for batch_id, (source_x, source_y) in tqdm(enumerate(unlabeled_source_dataloader), total=len(unlabeled_source_dataloader)):\n",
    "        source_x = source_x.to(device).view(-1, 3200).float()\n",
    "        source_y = source_y.to(device)\n",
    "        num_datas += source_x.shape[0]\n",
    "        source_x_embedding = encoder(source_x)\n",
    "        pred = CNet(source_x_embedding)\n",
    "        source_acc_unlabel += (pred.argmax(-1) == source_y).sum().item()\n",
    "        \n",
    "    source_acc_unlabel = source_acc_unlabel/num_datas\n",
    "    source_acc_unlabel_.append(source_acc_unlabel)\n",
    "    \n",
    "    # Assign Pesudo Label\n",
    "    correct_target = 0.0\n",
    "    target_pesudo_y = []\n",
    "    CNet.eval()\n",
    "    encoder.eval()\n",
    "    GNet.eval()\n",
    "    for batch in range(math.ceil(unlabeled_target_x.shape[0]/args.batch_size)):\n",
    "        target_unlabel_x_batch = torch.Tensor(unlabeled_target_x[batch*args.batch_size:(batch+1)*args.batch_size]).view(-1, 3200).to(device).float()\n",
    "        target_unlabel_y_batch = torch.Tensor(unlabeled_target_y[batch*args.batch_size:(batch+1)*args.batch_size]).to(device)        \n",
    "        # print(target_unlabel_y_batch.shape)\n",
    "        \n",
    "        target_unlabel_x_embedding = encoder(target_unlabel_x_batch)\n",
    "        fake_source_embedding = GNet(target_unlabel_x_embedding)\n",
    "        pred = CNet(fake_source_embedding)\n",
    "        correct_target += (pred.argmax(-1) == target_unlabel_y_batch).sum().item()\n",
    "        target_pesudo_y.extend(pred.argmax(-1).cpu().numpy())\n",
    "        \n",
    "    target_pesudo_y = np.array(target_pesudo_y)\n",
    "    pesudo_dict = get_class_data_dict(unlabeled_target_x, target_pesudo_y, num_class)\n",
    "    target_acc_unlabel = correct_target/(unlabeled_target_x.shape[0])\n",
    "    target_acc_unlabel_.append(target_acc_unlabel)\n",
    "    \n",
    "    logger.info('Epoch: %i, update classifier: source acc: %f; source unlbl acc: %f; target acc: %f; target unlabel acc: %f'%(epoch+1, source_acc, source_acc_unlabel, target_acc, target_acc_unlabel))\n",
    "\n",
    "    # Update GAN\n",
    "    if args.isglobal:\n",
    "        # Update global Discriminator\n",
    "        CNet.train()\n",
    "        encoder.train()\n",
    "        GNet.train()\n",
    "        DNet_local.train()\n",
    "        DNet_global.train()\n",
    "        total_error_D_global = 0\n",
    "        total_error_G = 0\n",
    "        for batch_id, ((source_x, source_y), (target_x, target_y)) in tqdm(enumerate(join_dataloader), total=len(join_dataloader)):\n",
    "            optimizerD_global.zero_grad()\n",
    "            optimizerG.zero_grad()\n",
    " \n",
    "            source_data = source_x.view(-1, 3200).to(device).float()\n",
    "            source_embedding = encoder(source_data)\n",
    "            target_data = target_x.view(-1, 3200).to(device).float()\n",
    "            target_embedding = encoder(target_data)\n",
    "            fake_source_embedding = GNet(target_embedding)\n",
    "            \"\"\"Update G Network\"\"\"     \n",
    "\n",
    "            # adversarial loss\n",
    "            loss_G = -DNet_global(fake_source_embedding,1).mean()\n",
    "\n",
    "            total_error_G += loss_G.item() * args.dglobal\n",
    "\n",
    "            loss_G.backward()\n",
    "            optimizerG.step()\n",
    "            \n",
    "\n",
    "            if batch_id % int(1/args.n_critic) == 0:\n",
    "                \"\"\"Update D Net\"\"\"\n",
    "                optimizerD_global.zero_grad()\n",
    "                source_data = source_x.to(device).view(-1, 3200).float()\n",
    "                source_embedding = encoder(source_data)\n",
    "                target_data = target_x.to(device).view(-1, 3200).float()\n",
    "                target_embedding = encoder(target_data)\n",
    "                fake_source_embedding = GNet(target_embedding).detach()\n",
    "                # adversarial loss\n",
    "                loss_D_global = DNet_global(fake_source_embedding,1).mean() - DNet_global(source_embedding,1).mean()\n",
    "                gradient_penalty = _gradient_penalty_global(source_embedding, fake_source_embedding, DNet_global, num_class, device, args)\n",
    "\n",
    "                loss_D_global = loss_D_global + gradient_penalty\n",
    "                loss_D_global = loss_D_global * args.dglobal\n",
    "                total_error_D_global += loss_D_global.item()\n",
    "\n",
    "                loss_D_global.backward()\n",
    "                optimizerD_global.step()\n",
    "\n",
    "#             # Clip weights of discriminator\n",
    "#             for p in DNet_global.parameters():\n",
    "#                 p.data.clamp_(-args.clip_value, args.clip_value)\n",
    "\n",
    "            #if batch_id % args.n_critic == 0:\n",
    "\n",
    "        \n",
    "        logger.info('Epoch: %i, Global Discrimator Updates: Loss D_global: %f, Loss G: %f; update_ratio: %i'%(epoch+1, total_error_D_global, total_error_G, int(1/args.n_critic)))\n",
    "\n",
    "        error_D_global.append(total_error_D_global)\n",
    "        error_G_global.append(total_error_G)\n",
    "\n",
    "    if args.islocal:\n",
    "        # Update local Discriminator\n",
    "        total_error_D_local = 0\n",
    "        total_error_G = 0\n",
    "        encoder.eval()\n",
    "\n",
    "        GNet.train()\n",
    "        DNet_local.train()\n",
    "\n",
    "        update_id = int(1/args.n_critic)\n",
    "        if args.pure_random:\n",
    "            update_id = max(1, update_id + np.random.randint(-2,2,1)[0])\n",
    "    #     elif args.adaptive_random:\n",
    "    #         if batch_id > 10:\n",
    "\n",
    "    #             # mean of last 10 trail\n",
    "    #             sd_Gloss = np.std(error_G_local[-10:])\n",
    "    #             sd_Dlocalloss = np.std(error_D_local[-10:])\n",
    "    #             update_id = update_id + np.random.randint(-2,2,1)[0]\n",
    "        for batch_id in tqdm(range(math.ceil(label_target_len/args.batch_size))):\n",
    "            target_x, target_y, target_weight = get_batch_target_data_on_class(target_labeled_dict, args.num_per_class, pesudo_dict, no_pesudo=True)\n",
    "            source_x, source_y = get_batch_source_data_on_class(source_labeled_dict, args.num_per_class)\n",
    "\n",
    "            source_x = torch.Tensor(source_x).view(-1, 3200).to(device).float()\n",
    "            target_x = torch.Tensor(target_x).view(-1, 3200).to(device).float()\n",
    "            source_y = torch.LongTensor(target_y).to(device)\n",
    "            target_y = torch.LongTensor(target_y).to(device)\n",
    "            target_weight = torch.Tensor(target_weight).to(device)\n",
    "            source_mask = torch.zeros(source_x.size(0), num_class).to(device).scatter_(1, source_y.unsqueeze(-1), 1)\n",
    "            target_mask = torch.zeros(target_x.size(0), num_class).to(device).scatter_(1, target_y.unsqueeze(-1), 1)\n",
    "            target_weight = torch.zeros(target_x.size(0), num_class).to(device).scatter_(1, target_y.unsqueeze(-1), target_weight.unsqueeze(-1))\n",
    "\n",
    "\n",
    "            source_weight_count = source_mask.sum(dim=0)\n",
    "            target_weight_count = target_weight.sum(dim=0)\n",
    "\n",
    "            if args.n_critic > 1:\n",
    "                \"\"\"Update D Net\"\"\"\n",
    "                optimizerD_local.zero_grad()\n",
    "                source_embedding = encoder(source_x)\n",
    "                target_embedding = encoder(target_x)\n",
    "                fake_source_embedding = GNet(target_embedding).detach()\n",
    "\n",
    "                # adversarial loss\n",
    "                source_DNet_local = DNet_local(source_embedding, source_mask)\n",
    "                target_DNet_local = DNet_local(fake_source_embedding, target_mask)\n",
    "\n",
    "                source_weight_count = source_mask.sum(dim=0)\n",
    "                target_weight_count = target_weight.sum(dim=0)\n",
    "\n",
    "                source_DNet_local_mean = source_DNet_local.sum(dim=0) / source_weight_count\n",
    "                target_DNet_local_mean = (target_DNet_local * target_weight).sum(dim=0) / target_weight_count        \n",
    "\n",
    "                gp = _gradient_penalty(source_embedding, fake_source_embedding, DNet_local, source_mask, num_class, device, args)\n",
    "\n",
    "                loss_D_local = (target_DNet_local_mean - source_DNet_local_mean + gp).sum()\n",
    "                loss_D_local = loss_D_local * args.dlocal\n",
    "\n",
    "                total_error_D_local += loss_D_local.item()\n",
    "\n",
    "                loss_D_local.backward()\n",
    "                optimizerD_local.step()\n",
    "\n",
    "                if batch_id % args.n_critic == 0:\n",
    "                    \"\"\"Update G Network\"\"\"\n",
    "                    optimizerG.zero_grad()\n",
    "                    optimizerEncoder.zero_grad()\n",
    "                    target_embedding = encoder(target_x)\n",
    "                    fake_source_embedding = GNet(target_embedding)\n",
    "\n",
    "                    # adversarial loss\n",
    "                    target_DNet_local = DNet_local(fake_source_embedding, target_mask)\n",
    "                    target_DNet_local_mean = (target_DNet_local * target_weight).sum(dim=0) / target_weight_count        \n",
    "\n",
    "                    loss_G = -target_DNet_local_mean.sum() \n",
    "                    loss_G = loss_G * args.dlocal\n",
    "\n",
    "                    total_error_G += loss_G.item()\n",
    "\n",
    "                    loss_G.backward()\n",
    "                    optimizerG.step()\n",
    "        #             optimizerEncoder.step()\n",
    "            else:\n",
    "                \"\"\"Update G Network\"\"\"\n",
    "                optimizerG.zero_grad()\n",
    "                optimizerEncoder.zero_grad()\n",
    "                target_embedding = encoder(target_x)\n",
    "                fake_source_embedding = GNet(target_embedding)\n",
    "\n",
    "                # adversarial loss\n",
    "                target_DNet_local = DNet_local(fake_source_embedding, target_mask)\n",
    "                target_DNet_local_mean = (target_DNet_local * target_weight).sum(dim=0) / target_weight_count        \n",
    "\n",
    "                loss_G = -target_DNet_local_mean.sum() \n",
    "                loss_G = loss_G * args.dlocal\n",
    "\n",
    "                total_error_G += loss_G.item()\n",
    "\n",
    "                loss_G.backward()\n",
    "                optimizerG.step()\n",
    "\n",
    "\n",
    "                if batch_id % update_id == 0:\n",
    "                    \"\"\"Update D Net\"\"\"\n",
    "                    optimizerD_local.zero_grad()\n",
    "                    source_embedding = encoder(source_x)\n",
    "                    target_embedding = encoder(target_x)\n",
    "                    fake_source_embedding = GNet(target_embedding).detach()\n",
    "\n",
    "                    # adversarial loss\n",
    "                    source_DNet_local = DNet_local(source_embedding, source_mask)\n",
    "                    target_DNet_local = DNet_local(fake_source_embedding, target_mask)\n",
    "\n",
    "                    source_DNet_local_mean = source_DNet_local.sum(dim=0) / source_weight_count\n",
    "                    target_DNet_local_mean = (target_DNet_local * target_weight).sum(dim=0) / target_weight_count        \n",
    "\n",
    "                    gp = _gradient_penalty(source_embedding, fake_source_embedding, DNet_local, source_mask, num_class, device, args)\n",
    "\n",
    "                    loss_D_local = (target_DNet_local_mean - source_DNet_local_mean + gp).sum()\n",
    "                    loss_D_local = loss_D_local * args.dlocal\n",
    "\n",
    "                    total_error_D_local += loss_D_local.item()\n",
    "\n",
    "                    loss_D_local.backward()\n",
    "                    optimizerD_local.step()\n",
    "\n",
    "        logger.info('Epoch: %i, Local Discrimator Updates: Loss D_local: %f, Loss G: %f; update_ratio: %i'%(epoch+1, total_error_D_local, total_error_G, update_id))\n",
    "        error_D_local.append(total_error_D_local)\n",
    "        error_G_global.append(total_error_G)\n",
    "\n",
    "    np.save(os.path.join(args.save_path, model_sub_folder, 'target_acc_label_.npy'),target_acc_label_)\n",
    "    np.save(os.path.join(args.save_path, model_sub_folder, 'source_acc_.npy'),source_acc_)\n",
    "    np.save(os.path.join(args.save_path, model_sub_folder, 'target_acc_unlabel_.npy'),target_acc_unlabel_)\n",
    "    np.save(os.path.join(args.save_path, model_sub_folder, 'source_acc_unlabel_.npy'),source_acc_unlabel_)\n",
    "    if args.isglobal:\n",
    "        np.save(os.path.join(args.save_path, model_sub_folder, 'error_D_global.npy'),error_D_global)\n",
    "        np.save(os.path.join(args.save_path, model_sub_folder, 'error_G_global.npy'),error_G_global)\n",
    "    if args.islocal:\n",
    "        np.save(os.path.join(args.save_path, model_sub_folder, 'error_D_local.npy'),error_D_local)\n",
    "        np.save(os.path.join(args.save_path, model_sub_folder, 'error_G_local.npy'),error_G_local)\n",
    "\n",
    "    if epoch % args.model_save_period == 0:\n",
    "        torch.save(CNet.state_dict(), os.path.join(args.save_path,model_sub_folder, 'CNet_%i.t7'%(epoch+1)))\n",
    "        torch.save(GNet.state_dict(), os.path.join(args.save_path,model_sub_folder, 'GNet_%i.t7'%(epoch+1)))\n",
    "        torch.save(encoder.state_dict(), os.path.join(args.save_path,model_sub_folder,'encoder_%i.t7'%(epoch+1)))\n",
    "        if args.isglobal:\n",
    "            torch.save(DNet_global.state_dict(),  os.path.join(args.save_path,model_sub_folder,'DNet_global_%i.t7'%(epoch+1)))\n",
    "        if args.islocal:\n",
    "            torch.save(DNet_local.state_dict(), os.path.join(args.save_path,model_sub_folder, 'DNet_local_%i.t7'%(epoch+1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(-3,3,1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_G_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.816496580927726"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
