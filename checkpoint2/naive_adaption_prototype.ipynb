{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, inspect\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, parent_dir)\n",
    "sys.path.insert(0, os.path.join(parent_dir,'spring-break'))\n",
    "sys.path.insert(0, os.path.join(parent_dir,'Linear Classifier'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from martins.complex_transformer import ComplexTransformer\n",
    "from FNNLinear import FNNLinear\n",
    "from FNNSeparated import FNNSeparated\n",
    "from GAN import Generator, Discriminator\n",
    "from data_utils import *\n",
    "import argparse\n",
    "import logging\n",
    "import logging.handlers\n",
    "import pickle\n",
    "from centerloss import CenterLoss\n",
    "from DataSetLoader import JoinDataset, SingleDataset\n",
    "from torch.autograd import Variable\n",
    "from binaryloss import BinaryLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--data_path DATA_PATH] [--task TASK]\n",
      "                             [--gpu_num GPU_NUM] [--batch_size BATCH_SIZE]\n",
      "                             [--epochs EPOCHS] [--lr_FNN LR_FNN]\n",
      "                             [--lr_encoder LR_ENCODER]\n",
      "                             [--lr_centerloss LR_CENTERLOSS] [--sclass SCLASS]\n",
      "                             [--scent SCENT] [--lr_gan LR_GAN]\n",
      "                             [--target_lbl_percentage TARGET_LBL_PERCENTAGE]\n",
      "                             [--source_lbl_percentage SOURCE_LBL_PERCENTAGE]\n",
      "                             [--num_per_class NUM_PER_CLASS] [--seed SEED]\n",
      "                             [--save_path SAVE_PATH]\n",
      "                             [--model_save_period MODEL_SAVE_PERIOD]\n",
      "                             [--epoch_begin_prototype EPOCH_BEGIN_PROTOTYPE]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\Tianqin Li\\AppData\\Roaming\\jupyter\\runtime\\kernel-460988ff-287e-4235-b5eb-83de570d2508.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tianqin Li\\anaconda3\\envs\\russ-local\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "parser = argparse.ArgumentParser(description='JDA Time series adaptation')\n",
    "parser.add_argument(\"--data_path\", type=str, default=\"/projects/rsalakhugroup/complex/domain_adaptation\", help=\"dataset path\")\n",
    "parser.add_argument(\"--task\", type=str, help='3A or 3E')\n",
    "parser.add_argument('--gpu_num', type=int, default=0, help='gpu number')\n",
    "parser.add_argument('--batch_size', type=int, default=256, help='batch size')\n",
    "parser.add_argument('--epochs', type=int, default=50, help='number of epochs')\n",
    "parser.add_argument('--lr_FNN', type=float, default=1e-3, help='learning rate for classification')\n",
    "parser.add_argument('--lr_encoder', type=float, default=1e-3, help='learning rate for classification')\n",
    "parser.add_argument('--lr_centerloss', type=float, default=0.005, help='learning rate for centerloss')\n",
    "parser.add_argument('--sclass', type=float, default=0.7, help='target classifier loss weight')\n",
    "parser.add_argument('--scent', type=float, default=0.0001, help='source domain classification weight on centerloss')\n",
    "parser.add_argument('--lr_gan', type=float, default=1e-3, help='learning rate for adversarial')\n",
    "parser.add_argument('--target_lbl_percentage', type=float, default=0.7, help='percentage of which target data has label')\n",
    "parser.add_argument('--source_lbl_percentage', type=float, default=0.7, help='percentage of which source data has label')\n",
    "parser.add_argument('--num_per_class', type=int, default=-1, help='number of sample per class when training local discriminator')\n",
    "parser.add_argument('--seed', type=int, default=0, help='manual seed')\n",
    "parser.add_argument('--save_path', type=str, help='where to store data')\n",
    "parser.add_argument('--model_save_period', type=int, default=2, help='period in which the model is saved')\n",
    "parser.add_argument('--epoch_begin_prototype', type=int, default=20, help='initial training period')\n",
    "parser.add_argument('--sprototype', type=float, default=1e-1, help='initial training period')\n",
    "\n",
    "\n",
    "args = parser.parse_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # local only\n",
    "# class local_args:\n",
    "#     def __init__(self, **entries):\n",
    "#         self.__dict__.update(entries)\n",
    "        \n",
    "# args = local_args(**{\n",
    "#     'data_path': '../data_unzip',\n",
    "#     'task': '3E',\n",
    "#     'num_class': 50,\n",
    "#     'batch_size': 100,\n",
    "#     'num_per_class': -1,\n",
    "#     'gap': 5,\n",
    "#     'lbl_percentage':0.7,\n",
    "#     'lr_gan': 1e-4,\n",
    "#     'lr_FNN': 1e-4,\n",
    "#     'lr_encoder': 1e-4,\n",
    "#     'epochs': 2,\n",
    "#     'clip_value': 0.01,\n",
    "#     'n_critic': 4,\n",
    "#     'sclass': 0.7,\n",
    "#     'scent': 1e-2,\n",
    "#     'seed': None,\n",
    "#     'save_path': '../train_related',\n",
    "#     'model_save_period': 1,\n",
    "#     'lr_centerloss': 1e-3,\n",
    "#     'lr_prototype': 1e-3,\n",
    "#     'sprototype': 1e-2,\n",
    "#     'seed': 0,\n",
    "#     'select_pretrain_epoch': 77,\n",
    "#     'epoch_begin_prototype': 0,\n",
    "#     'sbinary_loss': 1,\n",
    "#     'gpu_num': 0,\n",
    "#     'source_lbl_percentage': 0.7,\n",
    "#     'target_lbl_percentage': 0.7\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:{}'.format(args.gpu_num) if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# seed\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "cudnn.deterministic = True\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "args.task = '3Av2' if args.task == '3A' else '3E'\n",
    "num_class = 50 if args.task == \"3Av2\" else 65\n",
    "device = torch.device('cuda:{}'.format(args.gpu_num) if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if args.num_per_class == -1:\n",
    "    args.num_per_class = math.ceil(args.batch_size / num_class)\n",
    "    \n",
    "model_sub_folder = '/checkpoint2_prototype/naive_adaption/task_%s_slp_%f_tlp_%f_sclass_%f_scent_%f'%(args.task, args.source_lbl_percentage, args.target_lbl_percentage, args.sclass, args.scent)\n",
    "\n",
    "if not os.path.exists(args.save_path+model_sub_folder):\n",
    "    os.makedirs(args.save_path+model_sub_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_path: ../data_unzip\n",
      "task: 3E\n",
      "num_class: 50\n",
      "batch_size: 100\n",
      "num_per_class: 2\n",
      "gap: 5\n",
      "lbl_percentage: 0.7\n",
      "lr_gan: 0.0001\n",
      "lr_FNN: 0.0001\n",
      "lr_encoder: 0.0001\n",
      "epochs: 2\n",
      "clip_value: 0.01\n",
      "n_critic: 4\n",
      "sclass: 0.7\n",
      "scent: 0.01\n",
      "seed: 0\n",
      "save_path: ../train_related\n",
      "model_save_period: 1\n",
      "lr_centerloss: 0.001\n",
      "lr_prototype: 0.001\n",
      "sprototype: 0.01\n",
      "select_pretrain_epoch: 77\n",
      "epoch_begin_prototype: 0\n",
      "sbinary_loss: 1\n",
      "gpu_num: 0\n",
      "source_lbl_percentage: 0.7\n",
      "target_lbl_percentage: 0.7\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "if os.path.isfile(args.save_path+model_sub_folder+ '/logfile.log'):\n",
    "    os.remove(args.save_path+model_sub_folder+ '/logfile.log')\n",
    "    \n",
    "file_log_handler = logging.FileHandler(args.save_path+model_sub_folder+ '/logfile.log')\n",
    "logger.addHandler(file_log_handler)\n",
    "\n",
    "stdout_log_handler = logging.StreamHandler(sys.stdout)\n",
    "logger.addHandler(stdout_log_handler)\n",
    "\n",
    "attrs = vars(args)\n",
    "for item in attrs.items():\n",
    "    logger.info(\"%s: %s\"%item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_target_x_filename = '/processed_file_not_one_hot_%s_%1.1f_target_known_label_x.npy'%(args.task, args.target_lbl_percentage)\n",
    "labeled_target_y_filename = '/processed_file_not_one_hot_%s_%1.1f_target_known_label_y.npy'%(args.task, args.target_lbl_percentage)\n",
    "unlabeled_target_x_filename = '/processed_file_not_one_hot_%s_%1.1f_target_unknown_label_x.npy'%(args.task, args.target_lbl_percentage)\n",
    "unlabeled_target_y_filename = '/processed_file_not_one_hot_%s_%1.1f_target_unknown_label_y.npy'%(args.task, args.target_lbl_percentage)\n",
    "labeled_target_x = np.load(args.data_path+labeled_target_x_filename)\n",
    "labeled_target_y = np.load(args.data_path+labeled_target_y_filename)\n",
    "unlabeled_target_x = np.load(args.data_path+unlabeled_target_x_filename)\n",
    "unlabeled_target_y = np.load(args.data_path+unlabeled_target_y_filename)\n",
    "labeled_target_dataset = SingleDataset(labeled_target_x, labeled_target_y)\n",
    "unlabled_target_dataset = SingleDataset(unlabeled_target_x, unlabeled_target_y)\n",
    "labeled_target_dataloader = DataLoader(labeled_target_dataset, batch_size=args.batch_size, shuffle=True, pin_memory=True, num_workers=4)\n",
    "unlabeled_target_dataloader = DataLoader(unlabled_target_dataset, batch_size=args.batch_size, shuffle=False, pin_memory=True, num_workers=4)\n",
    "\n",
    "labeled_source_x_filename = '/processed_file_not_one_hot_%s_%1.1f_source_known_label_x.npy'%(args.task, args.source_lbl_percentage)\n",
    "labeled_source_y_filename = '/processed_file_not_one_hot_%s_%1.1f_source_known_label_y.npy'%(args.task, args.source_lbl_percentage)\n",
    "unlabeled_source_x_filename = '/processed_file_not_one_hot_%s_%1.1f_source_unknown_label_x.npy'%(args.task, args.source_lbl_percentage)\n",
    "unlabeled_source_y_filename = '/processed_file_not_one_hot_%s_%1.1f_source_unknown_label_y.npy'%(args.task, args.source_lbl_percentage)\n",
    "labeled_source_x = np.load(args.data_path+labeled_source_x_filename)\n",
    "labeled_source_y = np.load(args.data_path+labeled_source_y_filename)\n",
    "unlabeled_source_x = np.load(args.data_path+unlabeled_source_x_filename)\n",
    "unlabeled_source_y = np.load(args.data_path+unlabeled_source_y_filename)\n",
    "labeled_source_dataset = SingleDataset(labeled_source_x, labeled_source_y)\n",
    "unlabled_source_dataset = SingleDataset(unlabeled_source_x, unlabeled_source_y)\n",
    "labeled_source_dataloader = DataLoader(labeled_source_dataset, batch_size=args.batch_size, shuffle=True, pin_memory=True, num_workers=4)\n",
    "unlabeled_source_dataloader = DataLoader(unlabled_source_dataset, batch_size=args.batch_size, shuffle=False, pin_memory=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "    elif type(m) == nn.LayerNorm:\n",
    "        torch.nn.init.normal_(m.weight, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:{}'.format(args.gpu_num) if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "seq_len = 10\n",
    "feature_dim = 160\n",
    "encoder = ComplexTransformer(layers=3,\n",
    "                               time_step=seq_len,\n",
    "                               input_dim=feature_dim,\n",
    "                               hidden_size=64,\n",
    "                               output_dim=64,\n",
    "                               num_heads=8,\n",
    "                               out_dropout=0.2,\n",
    "                               leaky_slope=0.2).to(device)\n",
    "encoder_MLP = FNNSeparated(d_in=64 * 2 * 1, d_h1=64*4, d_h2=64*2, dp=0.2).to(device)\n",
    "CNet = FNNLinear(d_h2=64*2, d_out=num_class).to(device)\n",
    "GNet = Generator(dim=64*2).to(device)\n",
    "\n",
    "criterion_centerloss = CenterLoss(num_classes=num_class, feat_dim=64*2, use_gpu=torch.cuda.is_available()).to(device)\n",
    "criterion_classifier = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "encoder.apply(weights_init)\n",
    "encoder_MLP.apply(weights_init)\n",
    "CNet.apply(weights_init)\n",
    "GNet.apply(weights_init)\n",
    "\n",
    "optimizerCNet = torch.optim.Adam(CNet.parameters(), lr=args.lr_FNN)\n",
    "optimizerEncoderMLP = torch.optim.Adam(encoder_MLP.parameters(), lr=args.lr_encoder)\n",
    "optimizerEncoder = torch.optim.Adam(encoder.parameters(), lr=args.lr_encoder)\n",
    "optimizerGNet = torch.optim.Adam(GNet.parameters(), lr=args.lr_gan)\n",
    "optimizerCenterLoss = torch.optim.Adam(criterion_centerloss.parameters(), lr=args.lr_centerloss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_inference(encoder, CNet, x):\n",
    "    CNet.eval()\n",
    "    encoder.eval()\n",
    "    with torch.no_grad():\n",
    "        embedding = encoder_inference(encoder, x)\n",
    "        pred = CNet(embedding)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_inference(encoder, encoder_MLP, x):\n",
    "    real = x[:,:,0].reshape(x.size(0), seq_len, feature_dim).float()\n",
    "    imag = x[:,:,1].reshape(x.size(0), seq_len, feature_dim).float()\n",
    "    real, imag = encoder(real, imag)\n",
    "    cat_embedding = torch.cat((real[:,-1,:], imag[:,-1,:]), -1).reshape(x.shape[0], -1)\n",
    "    cat_embedding = encoder_MLP(cat_embedding)\n",
    "    return cat_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean(samples, labels):\n",
    "    assert samples.size(0) == labels.size(0)\n",
    "    \"\"\"\n",
    "    samples = torch.Tensor([\n",
    "                         [0.1, 0.1],    #-> group / class 1\n",
    "                         [0.2, 0.2],    #-> group / class 2\n",
    "                         [0.4, 0.4],    #-> group / class 2\n",
    "                         [0.0, 0.0]     #-> group / class 0\n",
    "                  ])\n",
    "    labels = torch.LongTensor([1, 2, 2, 0])\n",
    "    return \n",
    "        tensor([[0.0000, 0.0000],\n",
    "                [0.1000, 0.1000],\n",
    "                [0.3000, 0.3000]])\n",
    "    \"\"\"\n",
    "    M = torch.zeros(labels.max()+1, len(samples)).to(device)\n",
    "    M[labels, torch.arange(len(samples))] = 1\n",
    "    M = torch.nn.functional.normalize(M, p=1, dim=1)\n",
    "    res = torch.mm(M, samples)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/99 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in pin memory thread for device 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\Tianqin Li\\anaconda3\\envs\\russ-local\\lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\", line 31, in _pin_memory_loop\n    data = pin_memory(data)\n  File \"C:\\Users\\Tianqin Li\\anaconda3\\envs\\russ-local\\lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\", line 55, in pin_memory\n    return [pin_memory(sample) for sample in data]\n  File \"C:\\Users\\Tianqin Li\\anaconda3\\envs\\russ-local\\lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\", line 55, in <listcomp>\n    return [pin_memory(sample) for sample in data]\n  File \"C:\\Users\\Tianqin Li\\anaconda3\\envs\\russ-local\\lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\", line 47, in pin_memory\n    return data.pin_memory()\nRuntimeError: cuda runtime error (710) : device-side assert triggered at ..\\aten\\src\\THC\\THCCachingHostAllocator.cpp:278\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-c3fc247cc13f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msource_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource_y\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabeled_source_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabeled_source_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0moptimizerCNet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0moptimizerEncoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\russ-local\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1127\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1128\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1129\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\russ-local\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\russ-local\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    854\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m                 \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 856\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\russ-local\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    880\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 881\u001b[1;33m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    882\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\russ-local\\lib\\site-packages\\torch\\_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[1;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: Caught RuntimeError in pin memory thread for device 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\Tianqin Li\\anaconda3\\envs\\russ-local\\lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\", line 31, in _pin_memory_loop\n    data = pin_memory(data)\n  File \"C:\\Users\\Tianqin Li\\anaconda3\\envs\\russ-local\\lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\", line 55, in pin_memory\n    return [pin_memory(sample) for sample in data]\n  File \"C:\\Users\\Tianqin Li\\anaconda3\\envs\\russ-local\\lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\", line 55, in <listcomp>\n    return [pin_memory(sample) for sample in data]\n  File \"C:\\Users\\Tianqin Li\\anaconda3\\envs\\russ-local\\lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\", line 47, in pin_memory\n    return data.pin_memory()\nRuntimeError: cuda runtime error (710) : device-side assert triggered at ..\\aten\\src\\THC\\THCCachingHostAllocator.cpp:278\n"
     ]
    }
   ],
   "source": [
    "source_acc_label_ = []\n",
    "source_acc_unlabel_ = []\n",
    "target_acc_label_ = []\n",
    "target_acc_unlabel_ = []\n",
    "\n",
    "logger.info('Started Training')\n",
    "for epoch in range(args.epochs):\n",
    "\n",
    "    # update classifier\n",
    "    # on source domain\n",
    "    CNet.train()\n",
    "    encoder.train()\n",
    "    encoder_MLP.train()\n",
    "    source_acc_label = 0.0\n",
    "    num_datas = 0.0\n",
    "    \n",
    "    source_x_embeddings = torch.empty(0).to(device)\n",
    "    source_ys = torch.empty(0, dtype=torch.long).to(device)\n",
    "    \n",
    "\n",
    "    for batch_id, (source_x, source_y) in tqdm(enumerate(labeled_source_dataloader), total=len(labeled_source_dataloader)):\n",
    "        optimizerCNet.zero_grad()\n",
    "        optimizerEncoder.zero_grad()\n",
    "        optimizerEncoderMLP.zero_grad()\n",
    "        optimizerCenterLoss.zero_grad()\n",
    "        source_x = source_x.to(device).float()\n",
    "        source_y = source_y.to(device)\n",
    "        num_datas += source_x.size(0)\n",
    "        source_x_embedding = encoder_inference(encoder, encoder_MLP, source_x)\n",
    "        source_x_embeddings = torch.cat([source_x_embeddings, source_x_embedding])\n",
    "        source_ys = torch.cat([source_ys, source_y])\n",
    "        pred = CNet(source_x_embedding)\n",
    "        source_acc_label += (pred.argmax(-1) == source_y).sum().item()\n",
    "        loss = (criterion_classifier(pred, source_y) +\n",
    "                criterion_centerloss(source_x_embedding, source_y) * args.scent) * args.sclass\n",
    "        loss.backward()\n",
    "        optimizerCNet.step()\n",
    "        optimizerCenterLoss.step()\n",
    "        optimizerEncoderMLP.step()\n",
    "        optimizerEncoder.step()\n",
    "\n",
    "        \n",
    "    source_acc_label = source_acc_label / num_datas\n",
    "    source_acc_label_.append(source_acc_label)\n",
    "    \n",
    "    \n",
    "    # get center\n",
    "    source_centers = compute_mean(source_x_embeddings, source_ys) # (65, 128)\n",
    "    source_centers = source_centers.detach()\n",
    "    # on target domain\n",
    "    CNet.train()\n",
    "    encoder.train()\n",
    "    encoder_MLP.train()\n",
    "    target_acc_label = 0.0\n",
    "    num_datas = 0.0\n",
    "    for batch_id, (target_x, target_y) in tqdm(enumerate(labeled_target_dataloader), total=len(labeled_target_dataloader)):\n",
    "        optimizerCNet.zero_grad()\n",
    "        optimizerEncoder.zero_grad()\n",
    "        optimizerEncoderMLP.zero_grad()\n",
    "        optimizerGNet.zero_grad()\n",
    "        target_x = target_x.to(device).float()\n",
    "        target_y = target_y.to(device)\n",
    "        num_datas += target_x.size(0)\n",
    "        target_x_embedding = encoder_inference(encoder, encoder_MLP, target_x)\n",
    "        fake_x_embedding = GNet(target_x_embedding)\n",
    "        pred = CNet(fake_x_embedding)\n",
    "        target_acc_label += (pred.argmax(-1) == target_y).sum().item()\n",
    "        \n",
    "        \n",
    "        if epoch >= args.epoch_begin_prototype: \n",
    "            # prototype loss calculate\n",
    "            center_batch = source_centers[target_y, ]\n",
    "            dist = torch.sum(torch.pow(fake_x_embedding - center_batch, 2), axis=1)\n",
    "            # unique_class_y, class_count = torch.unique(target_y, return_counts=True)\n",
    "            prototype_loss = torch.mean(compute_mean(dist.view(-1,1), target_y))\n",
    "            # add prototype loss\n",
    "            loss = criterion_classifier(pred, target_y) + args.sprototype * prototype_loss\n",
    "        else:\n",
    "            loss = criterion_classifier(pred, target_y)\n",
    "        \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizerCNet.step()\n",
    "        optimizerGNet.step()\n",
    "        optimizerEncoderMLP.step()\n",
    "        optimizerEncoder.step()\n",
    "        \n",
    "    target_acc_label = target_acc_label / num_datas\n",
    "    target_acc_label_.append(target_acc_label)\n",
    "    \n",
    "    # eval\n",
    "    # source_domain\n",
    "    source_acc_unlabel = 0.0\n",
    "    num_datas = 0.0\n",
    "    CNet.eval()\n",
    "    encoder.eval()\n",
    "    encoder_MLP.eval()\n",
    "    for batch_id, (source_x, source_y) in tqdm(enumerate(unlabeled_source_dataloader), total=len(unlabeled_source_dataloader)):\n",
    "        source_x = source_x.to(device).float()\n",
    "        source_y = source_y.to(device)\n",
    "        num_datas += source_x.shape[0]\n",
    "        source_x_embedding = encoder_inference(encoder, encoder_MLP, source_x)\n",
    "        pred = CNet(source_x_embedding)\n",
    "        source_acc_unlabel += (pred.argmax(-1) == source_y).sum().item()\n",
    "        \n",
    "    source_acc_unlabel = source_acc_unlabel/num_datas\n",
    "    source_acc_unlabel_.append(source_acc_unlabel)\n",
    "    \n",
    "    # target_domain\n",
    "    target_acc_unlabel = 0.0\n",
    "    num_datas = 0.0\n",
    "    CNet.eval()\n",
    "    encoder.eval()\n",
    "    encoder_MLP.eval()\n",
    "    for batch_id, (target_x, target_y) in tqdm(enumerate(unlabeled_target_dataloader), total=len(unlabeled_target_dataloader)):\n",
    "        target_x = target_x.to(device).float()\n",
    "        target_y = target_y.to(device)\n",
    "        num_datas += target_x.shape[0]\n",
    "        target_x_embedding = encoder_inference(encoder, encoder_MLP, target_x)\n",
    "        fake_x_embedding = GNet(target_x_embedding)\n",
    "        pred = CNet(fake_x_embedding)\n",
    "        target_acc_unlabel += (pred.argmax(-1) == target_y).sum().item()\n",
    "        \n",
    "    target_acc_unlabel = target_acc_unlabel/num_datas\n",
    "    target_acc_unlabel_.append(target_acc_unlabel)\n",
    "    \n",
    "    if epoch % args.model_save_period == 0:\n",
    "        torch.save(encoder.state_dict(), args.save_path+model_sub_folder+ '/encoder_%i.t7'%(epoch+1))\n",
    "        torch.save(encoder_MLP.state_dict(), args.save_path+model_sub_folder+ '/encoder_MLP%i.t7'%(epoch+1))\n",
    "        torch.save(CNet.state_dict(), args.save_path+model_sub_folder+ '/CNet_%i.t7'%(epoch+1))\n",
    "        torch.save(GNet.state_dict(), args.save_path+model_sub_folder+ '/GNet_%i.t7'%(epoch+1))\n",
    "        torch.save(criterion_centerloss.state_dict(), args.save_path+model_sub_folder+ '/centerloss_%i.t7'%(epoch+1))\n",
    "\n",
    "\n",
    "    if epoch == args.epoch_begin_prototype:\n",
    "        logger.info('Start protoype;\\nEpochs %i: src labeled acc: %f; src unlabeled acc: %f; tgt labeled acc: %f; tgt unlabeled acc: %f'%(epoch+1, source_acc_label, source_acc_unlabel, target_acc_label, target_acc_unlabel))\n",
    "    else:\n",
    "            logger.info('Epochs %i: src labeled acc: %f; src unlabeled acc: %f; tgt labeled acc: %f; tgt unlabeled acc: %f'%(epoch+1, source_acc_label, source_acc_unlabel, target_acc_label, target_acc_unlabel))\n",
    "    np.save(args.save_path+model_sub_folder+'/target_acc_label_.npy', target_acc_label_)\n",
    "    np.save(args.save_path+model_sub_folder+'/target_acc_unlabel_.npy', target_acc_unlabel_)\n",
    "    np.save(args.save_path+model_sub_folder+'/source_acc_label_.npy', source_acc_label_)\n",
    "    np.save(args.save_path+model_sub_folder+'/source_acc_unlabel_.npy', source_acc_unlabel_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
